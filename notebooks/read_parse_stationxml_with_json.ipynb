{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read modified station XML files with extra metadata in Json format \n",
    "\n",
    "## Fei Zhang\n",
    "\n",
    "2020-07-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "\n",
    "our_new_station_xml =\"OA.CF28_station_inv_modified_json.xml\"  # add this stationxml into asdf file\n",
    "# VS extracted from ASDF\n",
    "#our_new_station_xml =\"OA.CF28_station_inv_modified_json_extracted_from_ASDF.xml\"\n",
    "\n",
    "our_inv = read_inventory(our_new_station_xml,format='STATIONXML')\n",
    "\n",
    "\n",
    "stn_meta = our_inv.networks[0].stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'obspy.core.util.attribdict.AttribDict'>\n",
      "AttribDict({'metadata_ga': AttribDict({'namespace': 'https://github.com/GeoscienceAustralia/hiperseis/xmlns/1.0', 'value': '\\n{\\n    \"network_code\":\"OA\",\\n    \"station_code\":\"CF28\",\\n\\n    \"orient_correction\": {\\n        \"start_dt\": \"2017-11-07T09:07:34.930000Z\",\\n        \"end_dt\":   \"2018-08-23T03:52:29.528000Z\",\\n        \"azimuth_correction\": -5.0\\n    },\\n\\n  \"gps_clock_corrections\": [\\n    {\\n      \"date\": \"2018-01-04\",\\n      \"seconds\": -1.3375814425470127\\n    },\\n    {\\n      \"date\": \"2018-01-05\",\\n      \"seconds\": -1.110449564656099\\n    },\\n    {\\n      \"date\": \"2018-01-06\",\\n      \"seconds\": -0.9032476255118933\\n    }\\n  ]\\n\\n}\\n'})})\n"
     ]
    }
   ],
   "source": [
    "print(type(stn_meta[0].extra))\n",
    "print(stn_meta[0].extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2018-06-09T06:21:41.000000Z\n",
      "2018-08-12T05:41:01.000000Z\n",
      "[]\n",
      "AttribDict({'metadata_ga': AttribDict({'namespace': 'https://github.com/GeoscienceAustralia/hiperseis/xmlns/1.0', 'value': '\\n{\\n    \"network_code\":\"OA\",\\n    \"station_code\":\"CF28\",\\n\\n    \"orient_correction\": {\\n        \"start_dt\": \"2017-11-07T09:07:34.930000Z\",\\n        \"end_dt\":   \"2018-08-23T03:52:29.528000Z\",\\n        \"azimuth_correction\": -5.0\\n    },\\n\\n  \"gps_clock_corrections\": [\\n    {\\n      \"date\": \"2018-08-12\",\\n      \"seconds\": -0.38272156676887814\\n    },\\n    {\\n      \"date\": \"2018-08-13\",\\n      \"seconds\": -0.38602834753320375\\n    },\\n    {\\n      \"date\": \"2018-08-14\",\\n      \"seconds\": -0.3893351282975293\\n    }\\n  ]\\n\\n}\\n  '})})\n"
     ]
    }
   ],
   "source": [
    "print(len(stn_meta))\n",
    "print(stn_meta[1].start_date)\n",
    "print(stn_meta[1].end_date)\n",
    "\n",
    "print(stn_meta[1].equipments)\n",
    "print(stn_meta[1].extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# extra_meta = our_inv.networks[0].stations[0].extra.gpsclockcorrection.value\n",
    "extra_meta = stn_meta[2].extra.metadata_ga.value\n",
    "print(type(extra_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"network_code\":\"OA\",\n",
      "    \"station_code\":\"CF28\",\n",
      "\n",
      "    \"orient_correction\": {\n",
      "        \"start_dt\": \"2017-11-07T09:07:34.930000Z\",\n",
      "        \"end_dt\":   \"2018-08-23T03:52:29.528000Z\",\n",
      "        \"azimuth_correction\": -5.0\n",
      "    },\n",
      "  \"gps_clock_corrections\": [\n",
      "    {\n",
      "      \"date\": \"2018-06-10\",\n",
      "      \"seconds\": -0.17439437861636772\n",
      "    },\n",
      "    {\n",
      "      \"date\": \"2018-06-11\",\n",
      "      \"seconds\": -0.17770115938069328\n",
      "    },\n",
      "    {\n",
      "      \"date\": \"2018-06-12\",\n",
      "      \"seconds\": -0.18100794014501886\n",
      "    }\n",
      "  ]\n",
      "\n",
      "}\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(extra_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'network_code': 'OA', 'station_code': 'CF28', 'orient_correction': {'start_dt': '2017-11-07T09:07:34.930000Z', 'end_dt': '2018-08-23T03:52:29.528000Z', 'azimuth_correction': -5.0}, 'gps_clock_corrections': [{'date': '2018-01-04', 'seconds': -1.3375814425470127}, {'date': '2018-01-05', 'seconds': -1.110449564656099}, {'date': '2018-01-06', 'seconds': -0.9032476255118933}]}\n",
      "dict_keys(['network_code', 'station_code', 'orient_correction', 'gps_clock_corrections'])\n",
      "<class 'list'>\n",
      "2018-01-04 -1.3375814425470127\n",
      "2018-01-05 -1.110449564656099\n",
      "2018-01-06 -0.9032476255118933\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "mdata = json.loads(extra_meta)\n",
    "\n",
    "print (mdata)\n",
    "print(mdata.keys())\n",
    "print(type(mdata['gps_clock_corrections']))\n",
    "\n",
    "for corr in mdata['gps_clock_corrections']:\n",
    "    print (corr[\"date\"], corr[\"seconds\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2018-01-04', 'seconds': -1.3375814425470127}, {'date': '2018-01-05', 'seconds': -1.110449564656099}, {'date': '2018-01-06', 'seconds': -0.9032476255118933}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (mdata['gps_clock_corrections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>-1.337581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>-1.110450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>-0.903248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   seconds\n",
       "0  2018-01-04 -1.337581\n",
       "1  2018-01-05 -1.110450\n",
       "2  2018-01-06 -0.903248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://pbpython.com/pandas-list-dict.html\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_clock_correction = pd.DataFrame(mdata['gps_clock_corrections'])\n",
    "df_clock_correction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   seconds\n",
      "0  2018-01-04 -1.337581\n",
      "1  2018-01-05 -1.110450\n",
      "2  2018-01-06 -0.903248\n"
     ]
    }
   ],
   "source": [
    "print (df_clock_correction.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   seconds\n",
      "0  2018-01-04 -1.337581\n"
     ]
    }
   ],
   "source": [
    "# get correction for a certain date YYYY-MM-DD\n",
    "print(df_clock_correction.loc[df_clock_correction[\"date\"] ==\"2018-01-04\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_clock_correction.query('date == \"2018-01-04\" ').seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "Name: date, dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clock_correction[\"date\"] ==\"2018-01-04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3375814425470127"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clock_correction.query('date == \"2018-01-04\" ').seconds.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.117093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.217243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.337581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.224016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.110450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.006849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-0.903248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        seconds\n",
       "count  3.000000\n",
       "mean  -1.117093\n",
       "std    0.217243\n",
       "min   -1.337581\n",
       "25%   -1.224016\n",
       "50%   -1.110450\n",
       "75%   -1.006849\n",
       "max   -0.903248"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clock_correction.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        object\n",
       "seconds    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clock_correction.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# What if there are more than one Station Node, such as AU.HTT in testdata/network_AU_0.xml, and OA.CF28 \n",
    "stations =our_inv.networks[0].stations\n",
    "print (len(stations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the output statoinXML file from ASDF\n",
    "\n",
    "We have added the input station xml into an ASDF file, then extract it out. See pyasdf_tests.ipynb\n",
    "\n",
    "## https://github.com/SeismicData/pyasdf/issues/63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "\n",
    "our_new_station_xml =\"OA.CF28_station_inv_modified_json_extracted_from_ASDF.xml\"\n",
    "our_inv = read_inventory(our_new_station_xml,format='STATIONXML')\n",
    "# print(our_inv.networks[0].stations[0].extra)\n",
    "\n",
    "stn_meta0 = our_inv.networks[0].stations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Station' object has no attribute 'extra'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8eceb316f6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstn_meta0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstn_meta0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Station' object has no attribute 'extra'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(stn_meta0.extra))\n",
    "print(stn_meta0.extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stn_meta0.start_date)\n",
    "print(stn_meta0.end_date)\n",
    "\n",
    "print(stn_meta0.equipments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with multiple station-nodes in a network.station inventory file\n",
    "\n",
    "See Jira: https://gajira.atlassian.net/browse/PV-130\n",
    "\n",
    " What if there are more than one Station Node, such as AU.HTT in testdata/network_AU_0.xml. \n",
    " And our_new_station_xml =\"OA.CF28_station_inv_modified_json.xml\"\n",
    " \n",
    "The multple station code represent the same station with different channel configuraiton over different time periods.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the modified xml file by running\n",
    "# python  add_time_corrections.py  /g/data/ha3/Passive/SHARED_DATA/GPS_Clock/corrections/AU.HTT_clock_correction.csv ../../tests/testdata/network_AU_0.xml \n",
    "\n",
    "def inspect_stations( our_new_station_xml ):\n",
    "    \n",
    "    our_inv = read_inventory(our_new_station_xml,format='STATIONXML')\n",
    "\n",
    "    #csv_str = our_inv.networks[0].stations[0].extra.gpsclockcorrection.value\n",
    "\n",
    "    stations =our_inv.networks[0].stations\n",
    "    \n",
    "    if len(stations)>=2:\n",
    "        print (our_new_station_xml)\n",
    "        print (\"Warning: more than one Station Node = %s\" %len(stations))\n",
    "    \n",
    "    return stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our_new_station_xml =\"/g/data/ha3/Passive/SHARED_DATA/GPS_Clock/StationXML_with_time_corrections2/AU.HTT_station_inv_modified.xml\"\n",
    "inspect_stations(our_new_station_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob\n",
    "\n",
    "xmlfolder = \"/g/data/ha3/Passive/SHARED_DATA/GPS_Clock/StationXML_with_time_corrections2/\"\n",
    "\n",
    "for axmlfile in glob.glob(os.path.join(xmlfolder,\"*.xml\")):\n",
    "    \n",
    "    stations = inspect_stations(axmlfile)\n",
    "    \n",
    "#     if len(stations)>=2:\n",
    "#         for astation in stations:\n",
    "#             print(\"### \", astation.code, astation.extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
