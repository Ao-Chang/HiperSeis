{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.width', 240)\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 100\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar helper to indicate that slow tasks have not stalled\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKS_PATH = r\"C:\\data_cache\\Picks\\20190219\\ensemble.p.txt\"\n",
    "#PICKS_PATH = r\"C:\\data_cache\\Picks\\20190219\\ensemble_small.p.txt\"\n",
    "dtype = {'#eventID': object,\n",
    "    'originTimestamp': np.float64,\n",
    "    'mag':                    np.float64,\n",
    "    'originLon':              np.float64,\n",
    "    'originLat':              np.float64,\n",
    "    'originDepthKm':          np.float64,\n",
    "    'net':                     object,\n",
    "    'sta':                     object,\n",
    "    'cha':                     object,\n",
    "    'pickTimestamp':          np.float64,\n",
    "    'phase':                   object,\n",
    "    'stationLon':             np.float64,\n",
    "    'stationLat':             np.float64,\n",
    "    'az':                     np.float64,\n",
    "    'baz':                    np.float64,\n",
    "    'distance':               np.float64,\n",
    "    'ttResidual':             np.float64,\n",
    "    'snr':                    np.float64,\n",
    "    'qualityMeasureCWT':      np.float64,\n",
    "    'domFreq':                np.float64,\n",
    "    'qualityMeasureSlope':    np.float64,\n",
    "    'bandIndex':              np.int64,\n",
    "    'nSigma':                 np.int64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_picks = pd.read_csv(PICKS_PATH, ' ', header=0, dtype=dtype)\n",
    "len(df_raw_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull up waveforms for outlier event\n",
    "import obspy\n",
    "\n",
    "print(obspy.UTCDateTime(df_raw_picks['originTimestamp'].min()))\n",
    "print(obspy.UTCDateTime(df_raw_picks['originTimestamp'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.fromtimestamp(0.0, datetime.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority order of trusted channels\n",
    "# channel_pref = ['BHZ_00', 'BHZ', 'BHZ_10', 'B?Z', 'S?Z', 'SHZ', '???', '?']\n",
    "channel_pref = ['BHZ_00', 'BHZ', 'BHZ_10', 'B?Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-BHZ channels as their picks are not considered reliable enough to use\n",
    "df_picks = df_raw_picks[df_raw_picks['cha'].isin(channel_pref)].reset_index()\n",
    "len(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused columns for readability\n",
    "df_picks = df_picks[['#eventID', 'originTimestamp', 'mag', 'originLon', 'originLat', 'originDepthKm', 'net', 'sta', 'cha', 'pickTimestamp', 'phase', \n",
    "                     'stationLon', 'stationLat', 'az', 'baz', 'distance', 'ttResidual', 'snr', 'qualityMeasureCWT', 'qualityMeasureSlope', 'nSigma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetworkStations(df, netcode):\n",
    "    return sorted(df[df['net'] == netcode]['sta'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetworkMean(df, netcode):\n",
    "    mean_lat = df[df['net'] == netcode]['stationLat'].mean()\n",
    "    mean_lon = df[df['net'] == netcode]['stationLon'].mean()\n",
    "    return (mean_lat, mean_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# REF_NET = 'AU'\n",
    "# REF_STN = 'MTN'\n",
    "#---\n",
    "# REF_NET = 'IR'\n",
    "# REF_STN = 'WRAB'\n",
    "#---\n",
    "# REF_NET = 'AU'\n",
    "# REF_STN = 'QIS' # Doesn't have much BHZ data\n",
    "#---\n",
    "# REF_NET = 'AU'\n",
    "# REF_STN = 'ARMA'\n",
    "#---\n",
    "REF_NET = 'AU'\n",
    "REF_STN = 'CMSA'\n",
    "#---\n",
    "# REF_NET = 'AU'\n",
    "# REF_STN = 'QLP'\n",
    "#---\n",
    "REF = {'net': [REF_NET], 'sta': [REF_STN]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# TARGET_NET = 'AU'\n",
    "# STN_LIST = ['KDU']\n",
    "#---\n",
    "# TARGET_NET = 'AU'\n",
    "# STN_LIST = ['WR0', 'WR1', 'WR2', 'WR3', 'WR4', 'WR5', 'WR6', 'WR7','WR8', 'WR9', 'WR10']\n",
    "#---\n",
    "# TARGET_NET = '7X'\n",
    "# STN_LIST = ['MA01', 'MA33', 'MA41', 'MA42', 'MA43', 'MA44', 'MA51', 'MA62', 'MIL7']\n",
    "#---\n",
    "TARGET_NET = '7D'\n",
    "STN_LIST = getNetworkStations(df_picks, TARGET_NET)\n",
    "STN_LIST = STN_LIST[0:16] # take a subset\n",
    "#---\n",
    "# TARGET_NET = '7G'\n",
    "# STN_LIST = getNetworkStations(df_picks, TARGET_NET)\n",
    "# STN_LIST = STN_LIST[0:22] # take a 1/3 subset\n",
    "#---\n",
    "# TARGET_NET = 'AU'\n",
    "# STN_LIST = ['ARMA']\n",
    "#---\n",
    "TARGET_STNS = {'net': [TARGET_NET]*len(STN_LIST), 'sta': [s for s in STN_LIST]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_styled_table(df):\n",
    "    # Display table with blocks of same event ID highlighted\n",
    "    df['lastEventID'] = df['#eventID'].shift(1)\n",
    "    df['lastEventID'].iloc[0] = df['#eventID'].iloc[0]\n",
    "    cols = ['#ffffff', '#e0e0ff']\n",
    "    def block_highlighter(r):\n",
    "        if r['lastEventID'] != r['#eventID']:\n",
    "            block_highlighter.current_col = (block_highlighter.current_col + 1) % len(cols)\n",
    "        return ['background-color: ' + cols[block_highlighter.current_col]]*len(r)\n",
    "    block_highlighter.current_col = 0\n",
    "    return df.style.apply(block_highlighter, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove reference station records where the SNR is too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ref_snr = 10\n",
    "mask_ref = df_picks[list(REF)].isin(REF).all(axis=1)\n",
    "mask_ref_snr = ~mask_ref | (mask_ref & (df_picks['snr'] >= min_ref_snr))\n",
    "df_good_ref_snr = df_picks.loc[mask_ref_snr]\n",
    "len(df_good_ref_snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to teleseismic events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column heading for the angular distance (degrees) between event and station\n",
    "ANG_DIST = 'distance'\n",
    "mask_tele = (df_good_ref_snr[ANG_DIST] >= 30.0) & (df_good_ref_snr[ANG_DIST] <= 90.0)\n",
    "df_tele = df_good_ref_snr.loc[mask_tele]\n",
    "len(df_tele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to constrained quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_cutoff = 15\n",
    "slope_cutoff = 3\n",
    "nsigma_cutoff = 4\n",
    "# cwt_cutoff = 0\n",
    "# slope_cutoff = 0\n",
    "# nsigma_cutoff = 0\n",
    "mask_cwt = (df_tele['qualityMeasureCWT'] >= cwt_cutoff)\n",
    "mask_slope = (df_tele['qualityMeasureSlope'] >= slope_cutoff)\n",
    "mask_sigma = (df_tele['nSigma'] >= nsigma_cutoff)\n",
    "# Make sure we DON'T filter out the reference station, which may have zero quality values\n",
    "mask_ref = df_tele[list(REF)].isin(REF).all(axis=1)\n",
    "quality_mask = (mask_cwt & mask_slope & mask_sigma) | mask_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.sum(quality_mask) > 100, 'Not enough points left after quality filtering'\n",
    "df_qual = df_tele[quality_mask]\n",
    "# df_qual = df_tele\n",
    "len(df_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_styled_table(df_qual[0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to desired ref and target networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ref = df_qual[list(REF)].isin(REF).all(axis=1)\n",
    "mask_targ = df_qual[list(TARGET_STNS)].isin(TARGET_STNS).all(axis=1)\n",
    "mask = mask_ref | mask_targ\n",
    "np.any(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nets = df_qual.loc[mask]\n",
    "len(df_nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out events in which REF and TARGET stations are not both present\n",
    "keep_events = [e for e, d in df_nets.groupby('#eventID') if np.any(d[list(REF)].isin(REF).all(axis=1)) and np.any(d[list(TARGET_STNS)].isin(TARGET_STNS).all(axis=1))]\n",
    "len(keep_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_mask = df_nets['#eventID'].isin(keep_events)\n",
    "df_nets = df_nets[event_mask]\n",
    "print(len(df_nets))\n",
    "assert len(df_nets) > 0, \"No events left to analyze!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few filtered entries\n",
    "#display_styled_table(df_nets[df_nets['#eventID'].isin(keep_events[0:5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias for dataset at the end of all filtering, a static name that can be used from here onwards.\n",
    "ds_final = df_nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each event, create column for reference traveltime residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for entire table first\n",
    "ds_final['ttResidualRef'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_duped = []\n",
    "pbar = tqdm(total=len(ds_final), ascii=True)\n",
    "for eventid, grp in ds_final.groupby('#eventID'):\n",
    "    pbar.update(len(grp))\n",
    "    ref_mask = (grp['net'] == REF['net'][0]) & (grp['sta'] == REF['sta'][0])\n",
    "    grp_ref = grp[ref_mask]\n",
    "    if grp_ref.empty:\n",
    "        continue\n",
    "    # Choose most favourable channel\n",
    "    cha = None\n",
    "    available_cha = grp_ref['cha'].values\n",
    "    for c in channel_pref:\n",
    "        if c in available_cha:\n",
    "            cha = c\n",
    "            break\n",
    "    # We must find a channel\n",
    "    if cha is None:\n",
    "        print(\"WARNING: Channels {} are not amongst allowed channels {}\".format(available_cha, channel_pref))\n",
    "        continue\n",
    "    cha_mask = (grp_ref['cha'] == cha)\n",
    "    grp_cha = grp_ref[cha_mask]\n",
    "    tt_ref_series = grp_cha['ttResidual'].unique()\n",
    "    if len(tt_ref_series) > 1:\n",
    "#         print(\"WARNING: Multiple reference times found for event {}\\n{},\"\n",
    "#               \" choosing smallest absolute residual\".format(eventid, grp_cha))\n",
    "        ref_duped.append(grp_ref)\n",
    "        # In this case, choose the smallest reference tt residual\n",
    "        grp_cha['absTTResidual'] = np.abs(grp_cha['ttResidual'].values)\n",
    "        grp_cha = grp_cha.sort_values('absTTResidual')\n",
    "        tt_ref_series = grp_cha['ttResidual'].unique()\n",
    "    ref_time = tt_ref_series[0]\n",
    "    ds_final.loc[grp.index, 'ttResidualRef'] = ref_time\n",
    "pbar.close()\n",
    "if ref_duped:\n",
    "    ref_duped_all = pd.concat(ref_duped)\n",
    "    ref_duped_all.to_csv(\"REF_ARRIVAL_DUPES.txt\", sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality check - each event should have only one unique reference tt residual\n",
    "assert np.all([len(df['ttResidualRef'].unique()) == 1 for e, df in ds_final.groupby('#eventID')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_final['relTtResidual'] = ds_final['ttResidual'] - ds_final['ttResidualRef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order columns\n",
    "ds_final = ds_final[['#eventID', 'originTimestamp', 'mag', 'originLon', 'originLat', 'originDepthKm', 'net', 'sta', 'cha', 'pickTimestamp', 'phase',\n",
    "                     'stationLon', 'stationLat', 'distance', 'snr', 'ttResidual', 'ttResidualRef', 'relTtResidual',\n",
    "                     'qualityMeasureCWT', 'qualityMeasureSlope', 'nSigma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display_styled_table(ds_final.iloc[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sort data by event origin time\n",
    "ds_final = ds_final.sort_values(['#eventID', 'originTimestamp'])\n",
    "#display_styled_table(ds_final.iloc[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandasTimestampToPlottableDatetime(data):\n",
    "    return data.transform(datetime.datetime.utcfromtimestamp).astype('datetime64[ms]').dt.to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTargetNetworkRelResiduals(df, target, ref, tt_scale=50, snr_scale=(0,60), save_file=False, file_label='', plot_aggregate=True, annotator=None):\n",
    "    \n",
    "    def plotDataset(ds, net_code, stn_code, ref_code):\n",
    "        tar_code = \".\".join([net_code, stn_code])\n",
    "        times = pandasTimestampToPlottableDatetime(ds['originTimestamp'])\n",
    "        vals = ds[yaxis].values\n",
    "        qual = ds['snr'].values\n",
    "        min_mag = 4.0\n",
    "        mag = ds['mag'].values - min_mag\n",
    "        relationship = '({}-{})'.format(tar_code, ref_code)\n",
    "        ylabel = 'Relative TT residual (sec){}'.format(relationship)\n",
    "        title = \"Station {} TT residual relative to {} (filtering: ref SNR$\\geq${}, CWT$\\geq${}, slope$\\geq${}, $n\\sigma\\geq{}$)\".format(\n",
    "            tar_code, ref_code, str(min_ref_snr), str(cwt_cutoff), str(slope_cutoff), str(nsigma_cutoff))\n",
    "        if len(vals) > 0:\n",
    "            plt.figure(figsize=(32,9))\n",
    "            sc = plt.scatter(times, vals, c=qual, alpha=0.5, cmap='gnuplot_r', s=np.maximum(50*mag, 1))\n",
    "            time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "            plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "            cb = plt.colorbar(sc, drawedges=False)\n",
    "            cb.set_label('Signal to noise ratio', fontsize=12)\n",
    "            plt.grid(color='#80808080', linestyle=':')\n",
    "            plt.xlabel(xlabel, fontsize=14)\n",
    "            plt.ylabel(ylabel, fontsize=14)\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.xlim(time_range)\n",
    "            plt.ylim((-tt_scale, tt_scale))\n",
    "            plt.clim(snr_scale)\n",
    "            plt.title(title, fontsize=18)\n",
    "            plt.legend(['Point size = Mag - {}, Color = SNR'.format(min_mag)], fontsize=12)\n",
    "            plt.text(0.01, 0.96, \"Channel selection: {}\".format(channel_pref), transform=plt.gca().transAxes, fontsize=12)\n",
    "            if annotator is not None:\n",
    "                annotator()\n",
    "            if save_file:\n",
    "                subfolder = os.path.join(net, ref_code)\n",
    "                os.makedirs(subfolder, exist_ok=True)\n",
    "                plt_file = os.path.join(subfolder, stn_code.replace(\"*\", \"{ast}\") + '_' + ylabel.replace(\" \", \"\").replace(\"*\", \"{ast}\") + file_label + \".png\")\n",
    "                plt.savefig(plt_file, dpi=150)    \n",
    "    # end plotDataset\n",
    "    \n",
    "    df_times = pandasTimestampToPlottableDatetime(df['originTimestamp'])\n",
    "    time_range = (df_times.min(), df_times.max())\n",
    "    yaxis='relTtResidual'\n",
    "    ref_code = \".\".join([ref['net'][0], ref['sta'][0]])\n",
    "    xlabel = 'Event Origin Timestamp'\n",
    "    for i, stn in enumerate(target['sta']):\n",
    "        net = target['net'][i]\n",
    "        df_sample = df.loc[(df['net'] == net) & (df['sta'] == stn), ['#eventID', 'originTimestamp', 'mag', 'net', 'sta', yaxis, 'snr',\\\n",
    "                                                                     'qualityMeasureCWT', 'qualityMeasureSlope', 'nSigma']]\n",
    "        plotDataset(df_sample, net, stn, ref_code)\n",
    "        \n",
    "    if plot_aggregate:\n",
    "        # Assumes only one network code in the target\n",
    "        mask_targ = df[list(target)].isin(target).all(axis=1)\n",
    "        df_agg = df[mask_targ]\n",
    "        plotDataset(df_agg, str(np.unique(target['net'])), '*', ref_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add7DMarkerLines():\n",
    "    for i, x in enumerate(np.array([1.354e9, 1.357e9, 1.362e9, 1.373e9])):\n",
    "        plt.axvline(x, linestyle='--', linewidth=2, alpha=0.5, color='C'+str(i//2))\n",
    "    plt.text(1.354e9, 40, 'Drift 1', horizontalalignment='right', fontsize=18, fontstyle='italic', alpha=0.6)\n",
    "    plt.text(1.373e9, 40, 'Drift 2', horizontalalignment='left', fontsize=18, fontstyle='italic', alpha=0.6)\n",
    "        \n",
    "plotTargetNetworkRelResiduals(ds_final, TARGET_STNS, REF, save_file=False, plot_aggregate=True)\n",
    "# plotTargetNetworkRelResiduals(ds_final, TARGET_STNS, REF, save_file=False, plot_aggregate=False, annotator=add7DMarkerLines)\n",
    "# plotTargetNetworkRelResiduals(ds_final[(ds_final['originTimestamp'] >= 1.35e9) & (ds_final['originTimestamp'] <= 1.38e9)],\n",
    "#                               TARGET_STNS, REF, save_file=False, plot_aggregate=False, annotator=add7DMarkerLines, file_label='(zoomed)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat, focusing on only results with high SNR\n",
    "# df_high_snr = ds_final[ds_final['snr'] >= 10.0]\n",
    "# plotTargetNetworkRelResiduals(df_high_snr, TARGET_STNS, REF, file_label='(high_SNR)', timeaxis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove REF_STN from dataset used for this plot.\n",
    "mask_targ_snr_plot = ds_final[list(TARGET_STNS)].isin(TARGET_STNS).all(axis=1)\n",
    "ds_snr_plot = ds_final[mask_targ_snr_plot]\n",
    "\n",
    "plt.figure(figsize=(32,9))\n",
    "\n",
    "COLOR_BY_DATE=True\n",
    "if COLOR_BY_DATE:\n",
    "    # Color by date\n",
    "    sc = plt.scatter(ds_snr_plot['relTtResidual'], ds_snr_plot['snr'], c=ds_snr_plot['pickTimestamp'].values, alpha=0.5, s=30*(ds_snr_plot['mag'] - 4))\n",
    "    cb = plt.colorbar(sc)\n",
    "    cb.set_label(\"Event Origin Timestamp\")\n",
    "    plt.legend(['Point size = Mag - 4.0, Color = Event Timestamp'], fontsize=12)\n",
    "else:\n",
    "    # Color by station code\n",
    "    stations = sorted(list(set(ds_snr_plot['sta'].unique())))\n",
    "    # print(stations)\n",
    "    colors = ['C' + str(n%10) for n in range(len(stations))]\n",
    "    # print(colors)\n",
    "    cdict = dict(zip(stations, colors))\n",
    "    cdict[REF_STN] = '#808080ff'\n",
    "    plt.scatter(ds_snr_plot['relTtResidual'], ds_snr_plot['snr'], c=ds_snr_plot['sta'].apply(lambda x: cdict[x]).values, alpha=0.5, s=20*(ds_snr_plot['mag'] - 4))\n",
    "    plt.legend(['Point size = Mag - 4.0, Color = station ID'], fontsize=12)\n",
    "\n",
    "plt.grid(color='#80808080', linestyle=':')\n",
    "plt.ylim((0,100))\n",
    "plt.xlim((-55,55))\n",
    "plt.xlabel(\"Relative TT residual (sec)\")\n",
    "plt.ylabel('SNR')\n",
    "plt.title(\"SNR vs relative TT residual across target network {}\".format(TARGET_NET))\n",
    "plt.savefig('SNR_vs_relTtResidual.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find extreme event for KDU\n",
    "# # mask = (ds_final['sta'] == 'KDU') & (ds_final['snr'] > 40) & (ds_final['relTtResidual'] < -25)\n",
    "# mask = (ds_final['sta'] == 'KDU') & (ds_final['snr'] > 40) & (ds_final['relTtResidual'] < -25) & (ds_final['mag'] > 5.5)\n",
    "# outlier = ds_final[mask]\n",
    "# outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_id = outlier['#eventID'].values[0]\n",
    "# event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_event = ds_final[ds_final['#eventID'] == event_id]\n",
    "# display_styled_table(df_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.display.float_format = '{:.1f}'.format\n",
    "# print(df_event[['#eventID', 'originTimestamp', 'mag', 'originLon', 'originLat', 'originDepthKm', 'net', 'sta', 'cha', \n",
    "#                 'pickTimestamp', 'phase', 'stationLon', 'stationLat', 'distance', 'ttResidual', 'relTtResidual', 'snr']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obspy.UTCDateTime(1299832266.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getNetworkMean(df_picks, '7D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
