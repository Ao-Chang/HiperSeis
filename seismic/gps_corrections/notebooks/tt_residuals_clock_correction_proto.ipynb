{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.width', 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "matplotlib.rcParams['figure.max_open_warning'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar helper to indicate that slow tasks have not stalled\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKS_PATH = r\"C:\\data_cache\\Picks\\20190219\\ensemble.p.txt\"\n",
    "#PICKS_PATH = r\"C:\\data_cache\\Picks\\20190219\\ensemble_small.p.txt\"\n",
    "dtype = {'#eventID': object,\n",
    "    'originTimestamp': np.float64,\n",
    "    'mag':                    np.float64,\n",
    "    'originLon':              np.float64,\n",
    "    'originLat':              np.float64,\n",
    "    'originDepthKm':          np.float64,\n",
    "    'net':                     object,\n",
    "    'sta':                     object,\n",
    "    'cha':                     object,\n",
    "    'pickTimestamp':          np.float64,\n",
    "    'phase':                   object,\n",
    "    'stationLon':             np.float64,\n",
    "    'stationLat':             np.float64,\n",
    "    'az':                     np.float64,\n",
    "    'baz':                    np.float64,\n",
    "    'distance':               np.float64,\n",
    "    'ttResidual':             np.float64,\n",
    "    'snr':                    np.float64,\n",
    "    'qualityMeasureCWT':      np.float64,\n",
    "    'domFreq':                np.float64,\n",
    "    'qualityMeasureSlope':    np.float64,\n",
    "    'bandIndex':              np.int64,\n",
    "    'nSigma':                 np.int64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_picks = pd.read_csv(PICKS_PATH, ' ', header=0, dtype=dtype)\n",
    "len(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priority order of trusted channels\n",
    "# channel_pref = ['BHZ_00', 'BHZ', 'BHZ_10', 'B?Z', 'S?Z', 'SHZ', '???', '?']\n",
    "channel_pref = ['BHZ_00', 'BHZ', 'BHZ_10', 'B?Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-BHZ channels as their picks are not considered reliable enough to use\n",
    "df_picks = df_picks[df_picks['cha'].isin(channel_pref)].reset_index()\n",
    "len(df_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unused columns for readability\n",
    "df_picks = df_picks[['#eventID', 'originTimestamp', 'mag', 'originLon', 'originLat', 'originDepthKm', 'net', 'sta', 'cha', 'pickTimestamp', 'phase', \n",
    "                     'stationLon', 'stationLat', 'az', 'baz', 'distance', 'ttResidual', 'snr', 'qualityMeasureCWT', 'qualityMeasureSlope', 'nSigma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF_NET = 'AU'\n",
    "# REF_STN = 'MTN'\n",
    "# REF_NET = 'IR'\n",
    "# REF_STN = 'WRAB'\n",
    "# REF_NET = 'AU'\n",
    "# REF_STN = 'QIS'\n",
    "REF_NET = 'AU'\n",
    "REF_STN = 'ARMA'\n",
    "REF = {'net': [REF_NET], 'sta': [REF_STN]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetworkStations(df, netcode):\n",
    "    return sorted(df[df['net'] == netcode]['sta'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNetworkMean(df, netcode):\n",
    "    mean_lat = df[df['net'] == netcode]['stationLat'].mean()\n",
    "    mean_lon = df[df['net'] == netcode]['stationLon'].mean()\n",
    "    return (mean_lat, mean_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET_NET = 'AU'\n",
    "# STN_LIST = ['KDU']\n",
    "# TARGET_NET = 'AU'\n",
    "# STN_LIST = ['WR0', 'WR1', 'WR2', 'WR3', 'WR4', 'WR5', 'WR6', 'WR7','WR8', 'WR9', 'WR10']\n",
    "# TARGET_NET = '7X'\n",
    "# STN_LIST = ['MA01', 'MA33', 'MA41', 'MA42', 'MA43', 'MA44', 'MA51', 'MA62', 'MIL7']\n",
    "TARGET_NET = '7D'\n",
    "STN_LIST = getNetworkStations(df_picks, TARGET_NET)\n",
    "STN_LIST = STN_LIST[0:12] # take a 1/4 subset\n",
    "TARGET_STNS = {'net': [TARGET_NET]*len(STN_LIST), 'sta': [s for s in STN_LIST]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_styled_table(df):\n",
    "    # Display table with blocks of same event ID highlighted\n",
    "    df['lastEventID'] = df['#eventID'].shift(1)\n",
    "    df['lastEventID'].iloc[0] = df['#eventID'].iloc[0]\n",
    "    cols = ['#ffffff', '#e0e0ff']\n",
    "    def block_highlighter(r):\n",
    "        if r['lastEventID'] != r['#eventID']:\n",
    "            block_highlighter.current_col = (block_highlighter.current_col + 1) % len(cols)\n",
    "        return ['background-color: ' + cols[block_highlighter.current_col]]*len(r)\n",
    "    block_highlighter.current_col = 0\n",
    "    return df.style.apply(block_highlighter, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove reference station records where the SNR is too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ref_snr = 10\n",
    "mask_ref = df_picks[list(REF)].isin(REF).all(axis=1)\n",
    "mask_ref_snr = ~mask_ref | (mask_ref & (df_picks['snr'] >= min_ref_snr))\n",
    "df_good_ref_snr = df_picks.loc[mask_ref_snr]\n",
    "len(df_good_ref_snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to teleseismic events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column heading for the angular distance (degrees) between event and station\n",
    "ANG_DIST = 'distance'\n",
    "mask_tele = (df_good_ref_snr[ANG_DIST] >= 30.0) & (df_good_ref_snr[ANG_DIST] <= 90.0)\n",
    "df_tele = df_good_ref_snr.loc[mask_tele]\n",
    "len(df_tele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to constrained quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwt_cutoff = 15\n",
    "slope_cutoff = 3\n",
    "nsigma_cutoff = 4\n",
    "mask_cwt = (df_tele['qualityMeasureCWT'] >= cwt_cutoff)\n",
    "mask_slope = (df_tele['qualityMeasureSlope'] >= slope_cutoff)\n",
    "mask_sigma = (df_tele['nSigma'] >= nsigma_cutoff)\n",
    "# Make sure we DON'T filter out the reference station, which may have zero quality values\n",
    "mask_ref = df_tele[list(REF)].isin(REF).all(axis=1)\n",
    "quality_mask = (mask_cwt & mask_slope & mask_sigma) | mask_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.sum(quality_mask) > 100, 'Not enough points left after quality filtering'\n",
    "df_qual = df_tele[quality_mask]\n",
    "# df_qual = df_tele\n",
    "len(df_qual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_styled_table(df_qual[0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to desired ref and target networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ref = df_qual[list(REF)].isin(REF).all(axis=1)\n",
    "mask_targ = df_qual[list(TARGET_STNS)].isin(TARGET_STNS).all(axis=1)\n",
    "mask = mask_ref | mask_targ\n",
    "np.any(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nets = df_qual.loc[mask]\n",
    "len(df_nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out events in which REF and TARGET stations are not both present\n",
    "keep_events = [e for e, d in df_nets.groupby('#eventID') if np.any(d[list(REF)].isin(REF).all(axis=1)) and np.any(d[list(TARGET_STNS)].isin(TARGET_STNS).all(axis=1))]\n",
    "len(keep_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_mask = df_nets['#eventID'].isin(keep_events)\n",
    "df_nets = df_nets[event_mask]\n",
    "len(df_nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few filtered entries\n",
    "#display_styled_table(df_nets[df_nets['#eventID'].isin(keep_events[0:5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alias for dataset at the end of all filtering, a static name that can be used from here onwards.\n",
    "ds_final = df_nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each event, create column for reference traveltime residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for entire table first\n",
    "ds_final['ttResidualRef'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_duped = []\n",
    "pbar = tqdm(total=len(ds_final), ascii=True)\n",
    "for eventid, grp in ds_final.groupby('#eventID'):\n",
    "    pbar.update(len(grp))\n",
    "    ref_mask = (grp['net'] == REF['net'][0]) & (grp['sta'] == REF['sta'][0])\n",
    "    grp_ref = grp[ref_mask]\n",
    "    if grp_ref.empty:\n",
    "        continue\n",
    "    # Choose most favourable channel\n",
    "    cha = None\n",
    "    available_cha = grp_ref['cha'].values\n",
    "    for c in channel_pref:\n",
    "        if c in available_cha:\n",
    "            cha = c\n",
    "            break\n",
    "    # We must find a channel\n",
    "    if cha is None:\n",
    "        print(\"WARNING: Channels {} are not amongst allowed channels {}\".format(available_cha, channel_pref))\n",
    "        continue\n",
    "    cha_mask = (grp_ref['cha'] == cha)\n",
    "    grp_cha = grp_ref[cha_mask]\n",
    "    tt_ref_series = grp_cha['ttResidual'].unique()\n",
    "    if len(tt_ref_series) > 1:\n",
    "#         print(\"WARNING: Multiple reference times found for event {}\\n{},\"\n",
    "#               \" choosing smallest absolute residual\".format(eventid, grp_cha))\n",
    "        ref_duped.append(grp_ref)\n",
    "        # In this case, choose the smallest reference tt residual\n",
    "        grp_cha['absTTResidual'] = np.abs(grp_cha['ttResidual'].values)\n",
    "        grp_cha = grp_cha.sort_values('absTTResidual')\n",
    "        tt_ref_series = grp_cha['ttResidual'].unique()\n",
    "    ref_time = tt_ref_series[0]\n",
    "    m = (grp_cha['ttResidual'] == ref_time)\n",
    "    ref_pick = grp_cha[m]['pickTimestamp'].iloc[0]\n",
    "    ds_final.loc[grp.index, 'ttResidualRef'] = ref_time\n",
    "    ds_final.loc[grp.index, 'pickTimestampRef'] = ref_pick\n",
    "pbar.close()\n",
    "if ref_duped:\n",
    "    ref_duped_all = pd.concat(ref_duped)\n",
    "    ref_duped_all.to_csv(\"REF_ARRIVAL_DUPES.txt\", sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality check - each event should have only one unique reference tt residual\n",
    "assert np.all([len(df['ttResidualRef'].unique()) == 1 for e, df in ds_final.groupby('#eventID')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_final['relTtResidual'] = ds_final['ttResidual'] - ds_final['ttResidualRef']\n",
    "ds_final['relPickTimestamp'] = ds_final['pickTimestamp'] - ds_final['pickTimestampRef']\n",
    "ds_final['relTtResidualAdjusted'] = ds_final['relTtResidual'] - ds_final['relPickTimestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order columns\n",
    "ds_final = ds_final[['#eventID', 'originTimestamp', 'mag', 'originLon', 'originLat', 'originDepthKm', 'net', 'sta', 'cha', 'pickTimestamp', 'phase',\n",
    "                     'stationLon', 'stationLat', 'distance', 'snr', 'ttResidual', 'ttResidualRef', 'relTtResidual', 'relPickTimestamp', 'relTtResidualAdjusted',\n",
    "                     'qualityMeasureCWT', 'qualityMeasureSlope', 'nSigma']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_styled_table(ds_final.iloc[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sort data by event origin time\n",
    "ds_final = ds_final.sort_values(['#eventID', 'originTimestamp'])\n",
    "#display_styled_table(ds_final.iloc[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTargetNetworkRelResiduals(df, target, ref, yaxis='relTtResidual', timeaxis=False, tt_scale=50, snr_scale=(0,60), file_label=''):\n",
    "    for i, stn in enumerate(target['sta']):\n",
    "        df_sample = df.loc[(df['net'] == target['net'][i]) & (df['sta'] == stn), ['#eventID', 'originTimestamp', 'mag', 'net', 'sta', yaxis, 'snr',\\\n",
    "                                                                                  'qualityMeasureCWT', 'qualityMeasureSlope', 'nSigma']]\n",
    "        rel_tt = df_sample[yaxis]\n",
    "        mask = ~rel_tt.isna().values\n",
    "        df_nonan = df_sample[mask]\n",
    "        df_nonan = df_nonan.reset_index()\n",
    "\n",
    "        if timeaxis:\n",
    "            times = df_nonan['originTimestamp'].astype(pd.Timestamp)\n",
    "            xaxis = 'Time'\n",
    "        else:\n",
    "            times = range(len(df_nonan))\n",
    "            xaxis = 'Sequence order'\n",
    "        vals = df_nonan[yaxis].values\n",
    "        qual = df_nonan['snr']\n",
    "        mag = df_nonan['mag'] - 4.0\n",
    "        if yaxis == 'relTtResidual':\n",
    "            label = 'Relative TT residual ({} relative to {})'.format(\".\".join([target['net'][i], stn]), \".\".join([ref['net'][0], ref['sta'][0]]))\n",
    "        else:\n",
    "            label = ''\n",
    "        title = \"With quality metric filtering (keep CWT$\\geq$\" + str(cwt_cutoff) + \", slope$\\geq$\" + str(slope_cutoff) + \", $n\\sigma\\geq\" + str(nsigma_cutoff) + \"$)\"\n",
    "        if len(vals) > 0:\n",
    "            plt.figure(figsize=(32,9))\n",
    "            if timeaxis:\n",
    "                sc = plt.scatter(times, vals, c=qual, alpha=0.5, cmap='gnuplot_r', s=50*mag)\n",
    "            else:\n",
    "                sc = plt.scatter(times, vals, c=qual, alpha=0.5, cmap='gnuplot_r', s=50*mag)\n",
    "            cb = plt.colorbar(sc)\n",
    "            cb.set_label('Signal to noise ratio')\n",
    "            plt.grid(color='#80808080', linestyle=':')\n",
    "            plt.xlabel(xaxis)\n",
    "            plt.ylabel(label)\n",
    "            plt.ylim((-tt_scale, tt_scale))\n",
    "            plt.clim(snr_scale)\n",
    "            plt.title(title)\n",
    "            plt.legend(['Point size = Mag - 4.0, Color = SNR'])\n",
    "            plt.savefig(stn + ' ' + label + file_label + \".png\", dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotTargetNetworkRelResiduals(ds_final, TARGET_STNS, REF, file_label='(all_SNR)', timeaxis=True)\n",
    "# plotTargetNetworkRelResiduals(ds_final, TARGET_STNS, REF, yaxis='relTtResidualAdjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat, focusing on only results with high SNR\n",
    "df_high_snr = ds_final[ds_final['snr'] >= 10.0]\n",
    "plotTargetNetworkRelResiduals(df_high_snr, TARGET_STNS, REF, file_label='(high_SNR)', timeaxis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32,9))\n",
    "stations = sorted(list(set(ds_final['sta'].unique()) - set([REF_STN])))\n",
    "# print(stations)\n",
    "colors = ['C' + str(n%10) for n in range(len(stations))]\n",
    "# print(colors)\n",
    "cdict = dict(zip(stations, colors))\n",
    "cdict[REF_STN] = '#808080ff'\n",
    "\n",
    "# Color by station code\n",
    "# plt.scatter(ds_final['relTtResidual'], ds_final['snr'], c=ds_final['sta'].apply(lambda x: cdict[x]).values, alpha=0.5, s=20*(ds_final['mag'] - 4))\n",
    "# Color by date\n",
    "plt.scatter(ds_final['relTtResidual'], ds_final['snr'], c=ds_final['pickTimestamp'].values, alpha=0.5, s=20*(ds_final['mag'] - 4))\n",
    "\n",
    "plt.grid(color='#80808080', linestyle=':')\n",
    "plt.ylim((0,100))\n",
    "# plt.xlim((-50,50))\n",
    "# plt.xlabel(label)\n",
    "plt.ylabel('SNR')\n",
    "# plt.title(title)\n",
    "plt.savefig('SNR_vs_relTtResidual.png', dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find extreme event for KDU\n",
    "# mask = (ds_final['sta'] == 'KDU') & (ds_final['snr'] > 40) & (ds_final['relTtResidual'] < -25)\n",
    "mask = (ds_final['sta'] == 'KDU') & (ds_final['snr'] > 40) & (ds_final['relTtResidual'] < -25) & (ds_final['mag'] > 5.5)\n",
    "outlier = ds_final[mask]\n",
    "outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = outlier['#eventID'].values[0]\n",
    "event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event = ds_final[ds_final['#eventID'] == event_id]\n",
    "display_styled_table(df_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "print(df_event[['#eventID', 'originTimestamp', 'mag', 'originLon', 'originLat', 'originDepthKm', 'net', 'sta', 'cha', \n",
    "                'pickTimestamp', 'phase', 'stationLon', 'stationLat', 'distance', 'ttResidual', 'relTtResidual', 'snr']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull up waveforms for outlier event\n",
    "# import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obspy.UTCDateTime(1299832266.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getNetworkMean(df_picks, '7D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
