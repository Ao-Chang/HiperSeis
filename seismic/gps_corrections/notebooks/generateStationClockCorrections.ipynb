{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze a cross-correlation to produce station clock correction file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to using this script, the quality of the correction should be visualized and confirmed using notebook `plotStationPairXcorr.ipynb`\n",
    "\n",
    "This notebook will generate a csv file with dates and estimated clock corrections for a given station. Applying the correction to the original ASDF database will be done separately for the sake of safety, so that any changes to ASDF must be very deliberate and intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import rrule\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.xcorqc.xcorr_station_clock_analysis import (XcorrPreprocessor, \n",
    "                                                         compute_estimated_clock_corrections,\n",
    "                                                         plot_estimated_timeshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILE = \"/g/data/ha3/am7399/shared/xcorr/7X/MA43_QIS/7X.MA43.AU.QIS.1.0-10.0.nc\"\n",
    "# SRC_FILE = \"/g/data/ha3/am7399/shared/xcorr/7X/MA52_QIS/7X.MA52.AU.QIS.1.0-10.0.nc\"\n",
    "# SRC_FILE = \"/g/data/ha3/am7399/dev/hiperseis/seismic/gps_corrections/7D_corrections/7D.DA41A.raw_clock_error.csv\"\n",
    "assert os.path.exists(SRC_FILE), \"File not found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, basename = os.path.split(SRC_FILE)\n",
    "_, file_type = os.path.splitext(SRC_FILE)\n",
    "name_parts = basename.split('.')\n",
    "NETCODE = name_parts[0]\n",
    "STATCODE = name_parts[1]\n",
    "print(\"Inferred target station code: {}.{}\".format(NETCODE, STATCODE))\n",
    "FULL_CODE = '.'.join([NETCODE, STATCODE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_type == \".nc\":\n",
    "    TIME_WINDOW = 300 # +/-\n",
    "    SNR_THRESHOLD = 6\n",
    "\n",
    "    xcorr_preproc = XcorrPreprocessor(SRC_FILE, TIME_WINDOW, SNR_THRESHOLD)\n",
    "    # flt_times is used for regression\n",
    "    flt_times = np.array([float(v) for v in xcorr_preproc.start_times])\n",
    "    # plt_times is used for plotting with human readable dates on the x-axis\n",
    "    plt_times = np.array([datetime.datetime.utcfromtimestamp(v) \n",
    "                          for v in xcorr_preproc.start_times]).astype('datetime64[ms]')\n",
    "\n",
    "    PCF_CUTOFF_THRESHOLD = 0.5\n",
    "    rcf_corrected, correction, row_rcf_crosscorr = \\\n",
    "        compute_estimated_clock_corrections(xcorr_preproc.rcf, xcorr_preproc.snr_mask,\n",
    "                                            xcorr_preproc.ccf_masked, xcorr_preproc.lag,\n",
    "                                            PCF_CUTOFF_THRESHOLD)\n",
    "elif file_type == \".csv\":\n",
    "    df_raw = pd.read_csv(SRC_FILE)\n",
    "    times = df_raw['originTimestamp'].values\n",
    "    correction = df_raw['rawClockError'].values\n",
    "    flt_times = np.array([float(v) for v in times])\n",
    "    plt_times = np.array([datetime.datetime.utcfromtimestamp(v) \n",
    "                          for v in times]).astype('datetime64[ms]')\n",
    "else:\n",
    "    assert False, \"Not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data for visual check\n",
    "if file_type == \".nc\":\n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    ax = plt.gca()\n",
    "    plot_estimated_timeshift(ax, xcorr_preproc.lag, xcorr_preproc.start_times, correction)\n",
    "    date_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "    date_locator = matplotlib.dates.WeekdayLocator(byweekday=rrule.SU)\n",
    "    ax.yaxis.set_major_formatter(date_formatter)\n",
    "    ax.yaxis.set_major_locator(date_locator)\n",
    "    ytl = ax.get_yticklabels()\n",
    "    for _ytl in ytl:\n",
    "        _ytl.set_visible(True)\n",
    "    ax.set_ylabel('Days')\n",
    "    ax.set_title('Computed clock corrections')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    ax = plt.gca()\n",
    "    plot_estimated_timeshift(ax, xcorr_preproc.lag, xcorr_preproc.start_times, correction, \n",
    "                             row_rcf_crosscorr=row_rcf_crosscorr)\n",
    "    ax.yaxis.set_major_formatter(date_formatter)\n",
    "    ax.yaxis.set_major_locator(date_locator)\n",
    "    ax.set_title('RCF * CCF used for corrections')\n",
    "\n",
    "    plt.suptitle('GPS Clock Corrections for {}'.format(xcorr_preproc.src_file), fontsize=16, y=0.92)\n",
    "    plt.show()\n",
    "elif file_type == \".csv\":\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.plot(plt_times, correction, 'x', markersize=10)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "    plt.ylabel('Raw estimate clock error (sec)', fontsize=14)\n",
    "    plt.title('Raw estimate clock corrections', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the corrections time series into coherent groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import dbscan\n",
    "from scipy import signal\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalDist2DSlope(p0, p1, coeffs):\n",
    "    return math.sqrt((coeffs[0] * (p1[0] - p0[0]))**2 + \n",
    "                     (coeffs[1] * sec_per_week*(p1[1] - p0[1]))**2 +\n",
    "                     (coeffs[2] * sec_per_week*sec_per_week*(p1[2] - p0[2]))**2)\n",
    "\n",
    "def calendarDist(p0, p1):\n",
    "    return abs(p1[0] - p0[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute slope metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(np.isnan(flt_times))\n",
    "nan_mask = np.isnan(correction)\n",
    "times_nonan = flt_times[~nan_mask]\n",
    "plt_times_nonan = plt_times[~nan_mask]\n",
    "correction_nonan = correction[~nan_mask]\n",
    "grad = np.gradient(correction_nonan, times_nonan, edge_order=1)\n",
    "grad_med5 = signal.medfilt(grad, 5)\n",
    "\n",
    "slope = grad_med5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_per_week = 7*24*3600\n",
    "\n",
    "tuned_coeffs = {\n",
    "    '7X.MA43': (1, 1, 20),\n",
    "    '7X.MA52': (1, 5, 15),\n",
    "    '7D.DA41A': (0.4, 0.3, 0.0)\n",
    "}\n",
    "\n",
    "assert FULL_CODE in tuned_coeffs, \"Add new coefficients for {}, then manually tune for fit\".FULL_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.column_stack((times_nonan, correction_nonan, slope))\n",
    "# ind, ids = dbscan(data, eps=2*sec_per_week, min_samples=7,\n",
    "#                   metric=calendarDist)\n",
    "ind, ids = dbscan(data, eps=2*sec_per_week, min_samples=7,\n",
    "                  metric=lambda p0, p1: temporalDist2DSlope(p0, p1, tuned_coeffs[FULL_CODE]))\n",
    "\n",
    "num_segments = len(set(ids[ids != -1]))\n",
    "print(\"{} clusters identified\".format(num_segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot clusters based on sample positions in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.plot(plt_times_nonan, correction_nonan, 'x', color=\"#808080\")\n",
    "for i in range(max(ids) + 1):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_nonan[mask_group], 'o-', color='C{}'.format(i),\n",
    "             markersize=6, fillstyle='none', alpha=0.7)\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} first order corrections groups\".format(FULL_CODE), fontsize=20)\n",
    "ylims = plt.ylim()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With successful segmentation, we perform regression for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of regressions, keyed by group ID\n",
    "regressions = {}\n",
    "\n",
    "# Corrections from regression function fit\n",
    "correction_fit = np.zeros_like(correction_nonan)\n",
    "correction_fit[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    # Perform regression\n",
    "    x = times_nonan[mask_group]\n",
    "    y = correction_nonan[mask_group]\n",
    "    r = np.polyfit(x, y, 1)\n",
    "    regressions[i] = r\n",
    "    # Compute fitted values\n",
    "    correction_fit[mask_group] = np.polyval(r, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replot with fitted line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_nonan[mask_group], 'o', color='C{}'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_fit[mask_group], color='C{}'.format(i))\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.ylim(ylims)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} corrections groups with regressions to sample times\".format(FULL_CODE), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample regression lines to the original sample times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of daily spaced time values and computed correction, since source data time\n",
    "# points might not be uniformly distributed. Keyed by group ID. These are the times\n",
    "# at which we will output corrections.\n",
    "regular_corrections = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_per_day = 24*3600\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    # Generate uniform daily times at which to compute corrections\n",
    "    x = times_nonan[mask_group]\n",
    "    timestamp_min = min(x)\n",
    "    timestamp_max = max(x)\n",
    "    num_days = np.round((timestamp_max - timestamp_min)/sec_per_day)\n",
    "    lin_times = np.linspace(timestamp_min, timestamp_max, num_days + 1)\n",
    "    lin_corrections = np.polyval(regressions[i], lin_times)\n",
    "    regular_corrections[i] = {'times': lin_times, 'corrections': lin_corrections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot to sanity check the final daily correction values\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_nonan[mask_group], 'o', color='#808080'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "    plt_times_i = np.array([datetime.datetime.utcfromtimestamp(v) for v in \n",
    "                            regular_corrections[i]['times']]).astype('datetime64[ms]')\n",
    "    plt.plot(plt_times_i, regular_corrections[i]['corrections'], 'o', color='C{}'.format(i), fillstyle='none')\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.ylim(ylims)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} corrections groups with regressions to daily samples\".format(FULL_CODE), fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FULL_CODE + \"_clock_correction_profile.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output regression results to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tabular format for ease of use and interoperability, even though there will be some redundancy of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_blocks = []\n",
    "for k in regular_corrections.keys():\n",
    "    c = regular_corrections[k]\n",
    "    # BEWARE: The 'corrections' array sign is negated there, since the correction\n",
    "    # we have computed up to this point is actually the clock *error*. Subtraction\n",
    "    # of an error is the same as addition of a correction of opposite sign.\n",
    "    data_blocks.append(pd.DataFrame(np.column_stack([c['times'], -c['corrections']]), \n",
    "                                    columns=['timestamp', 'clock_correction']))\n",
    "df = pd.concat(data_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['timestamp'].apply(obspy.UTCDateTime).apply(lambda x: x.date)\n",
    "df['net'] = NETCODE\n",
    "df['sta'] = STATCODE\n",
    "df = df[['net', 'sta', 'date', 'clock_correction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = FULL_CODE + \"_clock_correction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting corrections to file {}\".format(output_file))\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
