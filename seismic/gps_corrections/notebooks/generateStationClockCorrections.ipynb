{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze a cross-correlation to produce station clock correction file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to using this script, the quality of the correction should be visualized and confirmed using notebook `plotStationPairXcorr.ipynb`\n",
    "\n",
    "This notebook will generate a csv file with dates and estimated clock corrections for a given station. Applying the correction to the original ASDF database will be done separately for the sake of safety, so that any changes to ASDF must be very deliberate and intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import rrule\n",
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.xcorqc.xcorr_station_clock_analysis import (XcorrClockAnalyzer, \n",
    "                                                         plot_estimated_timeshift)\n",
    "from seismic.xcorqc.analytic_plot_utils import timestamps_to_plottable_datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILE = \"/g/data/ha3/Passive/SHARED_DATA/GPS_Clock/xcorr/AU/HTT_STKA/test/AU.HTT.AU.STKA.nc\"\n",
    "# SRC_FILE = \"/g/data/ha3/Passive/SHARED_DATA/GPS_Clock/xcorr/7X/MA43_QIS/7X.MA43.AU.QIS.1.0-10.0.nc\"\n",
    "# SRC_FILE = \"/g/data/ha3/Passive/SHARED_DATE/GPS_Clock/xcorr/7X/MA52_QIS/7X.MA52.AU.QIS.1.0-10.0.nc\"\n",
    "assert os.path.exists(SRC_FILE), \"File not found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, basename = os.path.split(SRC_FILE)\n",
    "_, file_type = os.path.splitext(SRC_FILE)\n",
    "name_parts = basename.split('.')\n",
    "NETCODE = name_parts[0]\n",
    "STATCODE = name_parts[1]\n",
    "print(\"Inferred target station code: {}.{}\".format(NETCODE, STATCODE))\n",
    "FULL_CODE = '.'.join([NETCODE, STATCODE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_WINDOW = 300 # +/-\n",
    "SNR_THRESHOLD = 6\n",
    "PCF_CUTOFF_THRESHOLD = 0.5\n",
    "\n",
    "xcorr_preproc = XcorrClockAnalyzer(SRC_FILE, TIME_WINDOW, SNR_THRESHOLD, PCF_CUTOFF_THRESHOLD)\n",
    "# flt_times is used for regression\n",
    "flt_times, correction = xcorr_preproc.get_corrections_time_series()\n",
    "\n",
    "# plt_times is used for plotting with human readable dates on the x-axis\n",
    "plt_times = timestamps_to_plottable_datetimes(flt_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the corrections time series into coherent groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_nonan = xcorr_preproc.correction_times_clean\n",
    "plt_times_nonan = timestamps_to_plottable_datetimes(times_nonan)\n",
    "correction_nonan = xcorr_preproc.corrections_clean\n",
    "slope = grad_med5 = xcorr_preproc.corrections_slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_coeffs = {\n",
    "    '7X.MA43': (1, 1, 20),\n",
    "    '7X.MA52': (1, 5, 15),\n",
    "    '7D.DA41A': (0.4, 0.3, 0.0),\n",
    "    'AU.HTT': (1, 1, 0)\n",
    "}\n",
    "\n",
    "assert FULL_CODE in tuned_coeffs, \"Add new coefficients for {}, then manually tune for fit\".FULL_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind, ids = xcorr_preproc.do_clustering(tuned_coeffs[FULL_CODE])\n",
    "num_segments = len(set(ids[ids != -1]))\n",
    "print(\"{} clusters identified\".format(num_segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot clusters based on sample positions in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "plt.plot(plt_times_nonan, correction_nonan, 'x', color=\"#808080\")\n",
    "for i in range(max(ids) + 1):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_nonan[mask_group], 'o-', color='C{}'.format(i),\n",
    "             markersize=6, fillstyle='none', alpha=0.7)\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} first order corrections groups\".format(FULL_CODE), fontsize=20)\n",
    "# ylims = plt.ylim()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With successful segmentation, we perform regression for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrections from regression function fit\n",
    "correction_fit = np.zeros_like(correction_nonan)\n",
    "correction_fit[:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting univariate spline\n",
    "degree = [1]*num_segments\n",
    "regressions = xcorr_preproc.do_spline_regression(ids, degree)\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    # Apply regression\n",
    "    x = times_nonan[mask_group]\n",
    "    # Compute fitted values\n",
    "    correction_fit[mask_group] = regressions[i](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replot with fitted line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_nonan[mask_group], 'o', color='C{}'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_fit[mask_group], color='C{}'.format(i))\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "# plt.ylim(ylims)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} corrections groups with regressions to sample times\".format(FULL_CODE), fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample regression lines to the original sample times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of daily spaced time values and computed correction, since source data time\n",
    "# points might not be uniformly distributed. Keyed by group ID. These are the times\n",
    "# at which we will output corrections.\n",
    "regular_corrections = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_per_day = 24*3600\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    # Generate uniform daily times at which to compute corrections\n",
    "    x = times_nonan[mask_group]\n",
    "    timestamp_min = min(x)\n",
    "    timestamp_max = max(x)\n",
    "    num_days = np.round((timestamp_max - timestamp_min)/sec_per_day)\n",
    "    lin_times = np.linspace(timestamp_min, timestamp_max, num_days + 1)\n",
    "    lin_corrections = regressions[i](lin_times)\n",
    "    regular_corrections[i] = {'times': lin_times, 'corrections': lin_corrections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot to sanity check the final daily correction values\n",
    "plt.figure(figsize=(16,9))\n",
    "\n",
    "for i in range(num_segments):\n",
    "    mask_group = (ids == i)\n",
    "    plt.plot(plt_times_nonan[mask_group], correction_nonan[mask_group], 'o', color='#808080'.format(i),\n",
    "             markersize=5, fillstyle='none')\n",
    "    plt_times_i = np.array([datetime.datetime.utcfromtimestamp(v) for v in \n",
    "                            regular_corrections[i]['times']]).astype('datetime64[ms]')\n",
    "    plt.plot(plt_times_i, regular_corrections[i]['corrections'], 'o', color='C{}'.format(i), fillstyle='none')\n",
    "\n",
    "time_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "plt.axes().xaxis.set_major_formatter(time_formatter)\n",
    "# plt.ylim(ylims)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(':', color=\"#808080\", zorder=0, alpha=0.5)\n",
    "plt.xlabel('Day', fontsize=14)\n",
    "plt.ylabel('Correction (sec)', fontsize=14)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.title(\"Station {} corrections groups with regressions to daily samples\".format(FULL_CODE), fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FULL_CODE + \"_clock_correction_profile.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output regression results to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use tabular format for ease of use and interoperability, even though there will be some redundancy of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_blocks = []\n",
    "for k in regular_corrections.keys():\n",
    "    c = regular_corrections[k]\n",
    "    # BEWARE: The 'corrections' array sign is negated there, since the correction\n",
    "    # we have computed up to this point is actually the clock *error*. Subtraction\n",
    "    # of an error is the same as addition of a correction of opposite sign.\n",
    "    data_blocks.append(pd.DataFrame(np.column_stack([c['times'], -c['corrections']]), \n",
    "                                    columns=['timestamp', 'clock_correction']))\n",
    "df = pd.concat(data_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['timestamp'].apply(obspy.UTCDateTime).apply(lambda x: x.date)\n",
    "df['net'] = NETCODE\n",
    "df['sta'] = STATCODE\n",
    "df = df[['net', 'sta', 'date', 'clock_correction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = FULL_CODE + \"_clock_correction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exporting corrections to file {}\".format(output_file))\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
