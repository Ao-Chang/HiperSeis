{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use public data to replicate C.Sippl (2016) *Technophysics* results Figure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, global setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import rf\n",
    "import rf.imaging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from obspy import UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismic.receiver_fn.rf_util as rf_util\n",
    "import seismic.receiver_fn.rf_plot_utils as rf_plot_utils\n",
    "import seismic.receiver_fn.rf_stacking as rf_stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data file of processed RF traces for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = '7W'\n",
    "# rf_type = 'ZRT_fd'\n",
    "rf_type = 'ZRT_td'\n",
    "data = rf_util.read_h5_rf(r\"..\\DATA\\7W_rfs_20080827T000136-20101231T235620_{}_qual.h5\".format(rf_type))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = set([tr.stats.station for tr in data])\n",
    "station_idx = {st: data.select(station=st) for st in stations}\n",
    "len(station_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_not_empty = set([st for st in station_idx if len(station_idx[st]) > 0])\n",
    "len(stations_not_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stations = sorted(stations_not_empty)\n",
    "print(test_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_station = 'BL05'\n",
    "# primary_station = 'BL20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data and present RF stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data down to only RF traces (filter out raw traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = data.select(station=primary_station)\n",
    "len(data_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first 100 RF plots\n",
    "# _ = rf_plot_utils.plot_rf_stack(data_rf.sort(['back_azimuth'])[0:100], time_window=(-5,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the main data channel code and set channel accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([tr.stats.channel for tr in data_rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'BHR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = data_rf.select(channel=channel)\n",
    "len(data_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate as much of Sippl's trace filtering logic as is amenable\n",
    "\n",
    "We do not replicate the criteria Sippl used of 80% match between R convolved with Z against the original (unconvolved) rotated R component, as this would require splitting apart the `rf` library function to compute RFs (separating the rotation and deconvolution steps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter RFs with too large amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_amp_cutoff = 2.0\n",
    "data_good = rf.RFStream([tr for tr in data_rf if tr.stats.log10_amp_max <= np.log10(max_amp_cutoff)])\n",
    "len(data_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by cross-correlation coefficient against other traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_crosscorr_coeff(rf_stream, time_window=(-2, 25)):\n",
    "    \"\"\"For each trace in the stream, compute its correlation coefficient with the other traces.\n",
    "    Return only traces matching cross correlation coefficient criteria based on Sippl.\n",
    "    \"\"\"\n",
    "    # Trim good RFs to time range so that subsequent cross-correlation computations relate to the relevant period around and after onset.\n",
    "    data_cc = rf_stream.copy().trim2(*time_window, reftime='onset')\n",
    "    # Gather all RFs into a single array for efficient computation of correlation coefficients between all traces\n",
    "    data_array = np.array([tr.data for tr in data_cc])\n",
    "    # Compute cross-correlation coefficients. cc matrix will be symmetric.\n",
    "    # Each row of cc indicates the degree of correlation between each other trace.\n",
    "    cc = np.corrcoef(data_array)\n",
    "    # Determine mask of which traces meet the similarity filtering criteria\n",
    "    threshold_cc = 0.70  # Denoted Xi in Sippl, who used value 0.80\n",
    "    fraction_above_threshold = np.sum(cc >= threshold_cc, axis=1)/len(data_cc)\n",
    "    min_fraction = 0.15  # Denoted tau in Sippl, who used value 0.15\n",
    "    keep_trace_mask = (fraction_above_threshold >= min_fraction)\n",
    "    kept_data = rf.RFStream([tr for i, tr in enumerate(rf_stream) if keep_trace_mask[i]])\n",
    "    return kept_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_good = filter_crosscorr_coeff(data_good, time_window=(-2, 20)).sort(['back_azimuth'])\n",
    "len(data_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = rf_plot_utils.plot_station_rf_overlays({channel: data_good}, time_range=(-5, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the good RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window=(-5.0, 30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'RF_stack_{}.{}.{}_{}_validation.png'.format(network, primary_station, channel, rf_type)\n",
    "fig = rf_plot_utils.plot_rf_stack(data_good, save_file=save_file, dpi=300, time_window=time_window)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H-k stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = rf_util.rf_to_dict(data_good)\n",
    "data_sta = db[primary_station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting = (0.5, 0.5, 0.0)\n",
    "weighting = (0.33, 0.33, 0.33)\n",
    "\n",
    "V_p = 6.4\n",
    "k_grid, h_grid, hk_stack = rf_stacking.compute_hk_stack(data_sta, channel, V_p=V_p, h_range=np.linspace(25.0, 75.0, 251),\n",
    "                                                        k_range=np.linspace(1.5, 2.0, 251), root_order=2)\n",
    "# Inferred V_p:\n",
    "# k_grid, h_grid, hk_stack = rf_stacking.compute_hk_stack(data_sta, channel, h_range=np.linspace(25.0, 75.0, 251),\n",
    "#                                                         k_range=np.linspace(1.5, 2.0, 251), root_order=2)\n",
    "\n",
    "# Sum the phases\n",
    "hk_stack_sum = rf_stacking.compute_weighted_stack(hk_stack, weighting)\n",
    "\n",
    "# Raise the final sum over phases to power >1 to increase contrast\n",
    "hk_stack_sum = rf_util.signed_nth_power(hk_stack_sum, 2)\n",
    "hk_stack_sum = hk_stack_sum/np.max(hk_stack_sum[:])\n",
    "\n",
    "# Numerically find location of maximum\n",
    "h_max, k_max = rf_stacking.find_global_hk_maximum(k_grid, h_grid, hk_stack_sum)\n",
    "print(\"Numerical solution (H, k) = ({:.3f}, {:.3f})\".format(h_max, k_max))\n",
    "\n",
    "sta = data_sta[channel][0].stats.station\n",
    "num = len(data_sta[channel])\n",
    "save_file = 'Hk_stack_{}.{}.{}_{}_validation.png'.format(network, sta, channel, rf_type)\n",
    "_ = rf_plot_utils.plot_hk_stack(k_grid, h_grid, hk_stack_sum, title='Station ' + sta + '.{}'.format(channel), num=num, save_file=save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend validation to cover other stations of Bilby deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_7W = rf_util.rf_to_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'csippl_validation_td_rev1'\n",
    "# output_folder = 'csippl_validation_fd_rev1'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_station in test_stations:\n",
    "    try:\n",
    "        db_station = db_7W[test_station]\n",
    "        channel = rf_util.choose_rf_source_channel(rf_type, db_station)\n",
    "\n",
    "        db_channel = db_station[channel]\n",
    "        test_rf = rf.RFStream(db_channel)\n",
    "\n",
    "        data_good = filter_crosscorr_coeff(data_good, time_window=(-2, 20)).sort(['back_azimuth'])\n",
    "        print(\"Num traces = {}\".format(len(data_good)))\n",
    "\n",
    "        save_file = 'RF_stack_{}.{}.{}_{}_validation.png'.format(network, test_station, channel, rf_type)\n",
    "        save_file = os.path.join(output_folder, save_file)\n",
    "        fig = rf_plot_utils.plot_rf_stack(data_good, save_file=save_file, dpi=300, time_window=time_window)\n",
    "\n",
    "        db_good = rf_util.rf_to_dict(data_good)\n",
    "        data_sta = db_good[test_station]\n",
    "\n",
    "#         weighting = (0.5, 0.5, 0.0)\n",
    "        weighting = (0.33, 0.33, 0.33)\n",
    "\n",
    "        V_p = 6.4\n",
    "        k_grid, h_grid, hk_stack = rf_stacking.compute_hk_stack(data_sta, channel, V_p=V_p, h_range=np.linspace(25.0, 75.0, 251),\n",
    "                                                                k_range=np.linspace(1.5, 2.0, 251), root_order=2)\n",
    "\n",
    "        # Sum the phases\n",
    "        hk_stack_sum = rf_stacking.compute_weighted_stack(hk_stack, weighting)\n",
    "\n",
    "        # Raise the final sum over phases to power >1 to increase contrast\n",
    "        hk_stack_sum = rf_util.signed_nth_power(hk_stack_sum, 2)\n",
    "        hk_stack_sum = hk_stack_sum/np.max(hk_stack_sum[:])\n",
    "\n",
    "        # Numerically find location of maximum\n",
    "        h_max, k_max = rf_stacking.find_global_hk_maximum(k_grid, h_grid, hk_stack_sum)\n",
    "        print(\"{}: Numerical solution (H, k) = ({:.3f}, {:.3f})\".format(test_station, h_max, k_max))\n",
    "\n",
    "        sta = test_station\n",
    "        num = len(data_sta[channel])\n",
    "        save_file = 'Hk_stack_{}.{}.{}_{}_validation.png'.format(network, sta, channel, rf_type)\n",
    "        save_file = os.path.join(output_folder, save_file)\n",
    "        _ = rf_plot_utils.plot_hk_stack(k_grid, h_grid, hk_stack_sum, title='Station ' + sta + '.{}'.format(channel), num=num, save_file=save_file)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Failed on station {} with error:\\n{}\".format(test_station, str(e)))\n",
    "    # end try\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
