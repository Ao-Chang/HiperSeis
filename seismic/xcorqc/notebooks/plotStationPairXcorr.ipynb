{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import dateutil\n",
    "from dateutil import rrule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.ASDFdatabase import FederatedASDFDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from analytic_plot_utils import distance\n",
    "from netCDF4 import Dataset as NCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for plotting\n",
    "from textwrap import wrap\n",
    "from scipy import signal\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station codes from file name\n",
    "def stationCodes(filename):\n",
    "    path, fname = os.path.split(filename)\n",
    "    parts = fname.split('.')\n",
    "    sta1 = '.'.join(parts[0:2])\n",
    "    sta2 = '.'.join(parts[2:4])\n",
    "    return (sta1, sta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationCoords(federated_ds, code, datetime):\n",
    "    ds = federated_ds\n",
    "    net, sta = code.split('.')\n",
    "    sta_records = ds.get_stations(datetime, obspy.UTCDateTime(datetime) + 3600*24*30, network=net, station=sta)\n",
    "    z_records = [r for r in sta_records if r[3][1:3] == 'HZ']\n",
    "    assert len(z_records) == 1, z_records\n",
    "    z_record = z_records[0]\n",
    "    return z_record[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationDistance(federated_ds, code1, code2, datetime):\n",
    "    coords1 = stationCoords(federated_ds, code1, datetime)\n",
    "    coords2 = stationCoords(federated_ds, code2, datetime)\n",
    "    return distance(coords1, coords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugLabelAxes(ax, label):\n",
    "    ax.text(0.5, 0.95, label, horizontalalignment='center', verticalalignment='top', transform=ax.transAxes, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestampToPlottableDatetime(data):\n",
    "    return data.transform(datetime.datetime.utcfromtimestamp).astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotXcorrTimeseries(ax, x_lag, y_times, xcorr_data):\n",
    "\n",
    "    np_times = np.array([datetime.datetime.utcfromtimestamp(v) for v in y_times]).astype('datetime64[s]')\n",
    "    gx, gy = np.meshgrid(x_lag, np_times)\n",
    "    im = ax.pcolormesh(gx, gy, xcorr_data, cmap='RdYlBu_r', vmin=0, vmax=1, rasterized=True)\n",
    "\n",
    "    use_formatter = False\n",
    "    if use_formatter:\n",
    "        date_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "        date_locator = matplotlib.dates.WeekdayLocator(byweekday=rrule.SU)\n",
    "        ax.yaxis.set_major_formatter(date_formatter)\n",
    "        ax.yaxis.set_major_locator(date_locator)\n",
    "    else:\n",
    "        labels = np.datetime_as_string(np_times, unit='D')\n",
    "        ax.set_yticks(np_times[::7])\n",
    "        ax.set_yticklabels(labels[::7])\n",
    "\n",
    "    ax.set_xlabel('Lag [s]')\n",
    "    ax.set_ylabel('Days')\n",
    "    \n",
    "    ax_pos = ax.get_position()\n",
    "    cax = plt.axes([ax_pos.x0 + 0.025, ax_pos.y1 - 0.1, 0.015, 0.08])\n",
    "\n",
    "    plt.colorbar(im, cax=cax, orientation='vertical', ticks=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRCF(ax, x_lag, rcf, snr_threshold):\n",
    "    if rcf is not None:\n",
    "        ax.axvline(x_lag[np.argmax(rcf)], c='#c66da9', lw=2,\n",
    "                    label = '{:5.2f} s'.format(x_lag[np.argmax(rcf)]))\n",
    "        ax.plot(x_lag, rcf, c='#42b3f4', \n",
    "                label=\"Reference CCF \\n\"\n",
    "                      \"Based on Subset \\n\"\n",
    "                      \"with SNR > {}\".format(snr_threshold))\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'REFERENCE CCF:\\nINSUFFICIENT SNR', horizontalalignment='center', \n",
    "         verticalalignment='center', transform=ax.transAxes, fontsize=16)\n",
    "\n",
    "    ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotStackedWindowCount(ax, x_nsw, y_times):\n",
    "    ax.plot(x_nsw, y_times, c='#529664')\n",
    "    ax.set_ylim((min(y_times), max(y_times)))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xlabel('\\n'.join(wrap('# of Hourly Stacked Windows', 12)))\n",
    "    xtl = ax.get_xticklabels()\n",
    "    xtl[0].set_visible(False)\n",
    "    xtl[-1].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSNRHistogram(ax, snr, time_window, nbins=10):\n",
    "    ax.hist(snr.compressed(), fc='#42b3f4', ec='none', bins=nbins)\n",
    "    ax.set_xlabel('SNR: Daily CCFs [-%d, %d]s'%(time_window, time_window))\n",
    "    ax.set_ylabel('Frequency')\n",
    "    xtl = ax.get_xticklabels()\n",
    "    xtl[0].set_visible(False)\n",
    "    xtl[-1].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPearsonCorrCoefficient(ax, rcf, ccf_masked, y_times):\n",
    "    cc = []\n",
    "    for row in ccf_masked:\n",
    "        if np.ma.is_masked(row) or rcf is None:\n",
    "            cc.append(np.nan)\n",
    "        else:\n",
    "            pcf, _ = scipy.stats.pearsonr(rcf, row)\n",
    "            cc.append(pcf)\n",
    "    # end for\n",
    "    pcf = np.array(cc)\n",
    "    # Compute CC mean\n",
    "    ccav = np.mean(np.ma.masked_array(pcf, mask=np.isnan(pcf)))\n",
    "\n",
    "    ax.plot(pcf, y_times, c='#d37f26')\n",
    "    ax.set_ylim((min(y_times), max(y_times)))\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks([0,1])\n",
    "    ax.set_xlabel('\\n'.join(wrap('Raw Pearson\\nCoeff. (vs RCF)', 15)))\n",
    "    ax.text(0.5, 0.98, '$PC_{av}$' + '={:3.3f}'.format(ccav), horizontalalignment='center', \\\n",
    "            verticalalignment='top', transform=ax.transAxes)\n",
    "    ax.axvline(ccav, c='#d37f26', linestyle='--', lw=2, linewidth=1, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotEstimatedTimeshift(ax, rcf, ccf_masked, x_lag, y_times, underlay_reference_corr=False):\n",
    "    correction = []\n",
    "    row_rcf_crosscorr = []\n",
    "    PCF_CUTOFF_THRESHOLD = 0.5\n",
    "    # Make an initial estimate of the shift, and only mask it out if the Pearson coefficient\n",
    "    # is less than the threshold AFTER applying the shift. Otherwise we will be masking out\n",
    "    # some of the most interesting regions where shifts occur.\n",
    "    for i, row in enumerate(ccf_masked):\n",
    "        if np.ma.is_masked(row) or rcf is None:\n",
    "            correction.append(np.nan)\n",
    "            row_rcf_crosscorr.append([np.nan]*ccf_masked.shape[1])\n",
    "            continue\n",
    "\n",
    "        # The logic here needs to be expanded to allow for possible mirroring of the CCF\n",
    "        # as well as a shift.\n",
    "        c3 = scipy.signal.correlate(rcf, row, mode='same')\n",
    "        c3 /= np.max(c3)\n",
    "        peak_index = np.argmax(c3)\n",
    "        shift_size = int(peak_index - len(c3)/2)\n",
    "        row_shifted = np.roll(row, shift_size)\n",
    "        if shift_size > 0:\n",
    "            row_shifted[0:shift_size] = 0\n",
    "        elif shift_size < 0:\n",
    "            row_shifted[shift_size:] = 0\n",
    "\n",
    "        pcf_corrected, _ = scipy.stats.pearsonr(rcf, row_shifted)\n",
    "\n",
    "        if pcf_corrected < PCF_CUTOFF_THRESHOLD:\n",
    "            correction.append(np.nan)\n",
    "            row_rcf_crosscorr.append([np.nan]*ccf_masked.shape[1])\n",
    "            continue\n",
    "\n",
    "        row_rcf_crosscorr.append(c3)\n",
    "        peak_lag = x_lag[peak_index]\n",
    "        correction.append(peak_lag)\n",
    "    # end for\n",
    "    correction = np.array(correction)\n",
    "    row_rcf_crosscorr = np.array(row_rcf_crosscorr)\n",
    "\n",
    "    if underlay_reference_corr and rcf is not None:\n",
    "        # Line plot laid over the top of RCF * CCF\n",
    "        np_times = np.array([datetime.datetime.utcfromtimestamp(v) for v in y_times]).astype('datetime64[s]')\n",
    "        gx, gy = np.meshgrid(x_lag, np_times)\n",
    "        plot_data = row_rcf_crosscorr\n",
    "        crange_floor = 0.7\n",
    "        plot_data[np.isnan(plot_data)] = crange_floor\n",
    "        plot_data[(plot_data < crange_floor)] = crange_floor\n",
    "        ax.pcolormesh(gx, gy, plot_data, cmap='RdYlBu_r', rasterized=True)\n",
    "        ax.set_ylim((min(np_times), max(np_times)))\n",
    "        xrange = 1.2*np.nanmax(np.abs(correction))\n",
    "        ax.set_xlim((-xrange, xrange))\n",
    "        col = '#ffffff'\n",
    "        p = ax.plot(correction, np_times, 'o--', color=col, fillstyle='none', markersize=4, alpha=0.8)\n",
    "#         ax.legend(p, ['Est. clock\\ncorrection'], loc=1)\n",
    "    else:\n",
    "        # Plain line plot\n",
    "        ax.plot(correction, y_times, 'o-', c='#f22e62', lw=1.5, fillstyle='none', markersize=4)\n",
    "        ax.set_ylim((min(y_times), max(y_times)))\n",
    "        ax.grid(\":\", color='#80808080')\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    xtl = ax.get_xticklabels()\n",
    "    xtl[0].set_visible(False)\n",
    "    xtl[-1].set_visible(False)\n",
    "    ax.set_xlabel('\\n'.join(wrap('Estimated Timeshift [s]: RCF * CCF', 15)))\n",
    "    ax.text(0.05, 0.98, 'Min. corrected Pearson Coeff={:3.3f}'.format(PCF_CUTOFF_THRESHOLD), color='#000000',\n",
    "            horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotXcorrFile(src_file, asdf_dataset, time_window, snr_threshold, show=True, pdf_file=None, png_file=None):\n",
    "    # Read xcorr data\n",
    "    xcdata = NCDataset(src_file, 'r')\n",
    "    # print(xcdata)\n",
    "\n",
    "    xc_start_times = xcdata.variables['IntervalStartTimes'][:] # sTimes\n",
    "    xc_end_times = xcdata.variables['IntervalEndTimes'][:] # eTimes\n",
    "    xc_lag = xcdata.variables['lag'][:] # lag\n",
    "    xc_xcorr = xcdata.variables['xcorr'][:, :] # xcorr\n",
    "    xc_nStackedWindows = xcdata.variables['NumStackedWindows'][:] # nStackedWindows\n",
    "    xcdata.close()\n",
    "    xcdata = None\n",
    "\n",
    "    start_utc_time = obspy.UTCDateTime(xc_start_times[0])\n",
    "    end_utc_time = obspy.UTCDateTime(xc_end_times[-1])\n",
    "    # print((start_utc_time, end_utc_time))\n",
    "\n",
    "    start_time = str(start_utc_time)\n",
    "    end_time = str(end_utc_time)\n",
    "    # print((start_time, end_time))\n",
    "\n",
    "    origin_code, dest_code = stationCodes(src_file)\n",
    "    dist = stationDistance(asdf_dataset, origin_code, dest_code, start_time)\n",
    "    # print(dist)\n",
    "    \n",
    "    # Extract primary data\n",
    "    lagIndices = np.squeeze(np.argwhere(np.fabs(np.round(xc_lag, decimals=2)) == time_window))\n",
    "    sTimes = xc_start_times\n",
    "    lag = xc_lag[lagIndices[0]:lagIndices[1]]\n",
    "    ccf = xc_xcorr[:, lagIndices[0]:lagIndices[1]]\n",
    "    nsw = xc_nStackedWindows\n",
    "\n",
    "    # Compute derived quantities used by multiple axes\n",
    "    zero_row_mask = (np.all(ccf == 0, axis=1))\n",
    "    valid_mask = np.ones_like(ccf)\n",
    "    valid_mask[zero_row_mask, :] = 0\n",
    "    valid_mask = (valid_mask > 0)\n",
    "    ccfMasked = np.ma.masked_array(ccf, mask=~valid_mask)\n",
    "    snr = np.nanmax(ccfMasked, axis=1) / np.nanstd(ccfMasked, axis=1)\n",
    "    if np.any(snr > snr_threshold):\n",
    "        rcf = np.nanmean(ccfMasked[(snr > snr_threshold), :], axis=0)\n",
    "    else:\n",
    "        rcf = None\n",
    "\n",
    "    #-----------------------------------------------------------------------\n",
    "    # Master layout and plotting code\n",
    "    \n",
    "    fig = plt.figure(figsize=(11.69,16.53))\n",
    "    fig.suptitle(\"Station: {}, Dist. to {}: {:3.2f} km\".format(origin_code, dest_code, dist), fontsize = 16, y=1)\n",
    "\n",
    "    ax1 = fig.add_axes([0.1, 0.075, 0.5, 0.725])\n",
    "    # debugLabelAxes(ax1, 'ax1')\n",
    "\n",
    "    labelPad = 0.05\n",
    "    ax2 = fig.add_axes([0.1, 0.8, 0.5, 0.175]) # reference CCF (accumulation of daily CCFs)\n",
    "    ax3 = fig.add_axes([0.6, 0.075, 0.1, 0.725]) # number of stacked windows\n",
    "    ax4 = fig.add_axes([0.6 + labelPad, 0.8 + 0.6*labelPad, 0.345, 0.175 - 0.6*labelPad]) # SNR histogram\n",
    "    ax5 = fig.add_axes([0.7, 0.075, 0.1, 0.725]) # Pearson coeff\n",
    "    ax6 = fig.add_axes([0.8, 0.075, 0.195, 0.725]) # estimate timeshifts\n",
    "    # debugLabelAxes(ax2, 'ax2')\n",
    "    # debugLabelAxes(ax3, 'ax3')\n",
    "    # debugLabelAxes(ax4, 'ax4')\n",
    "    # debugLabelAxes(ax5, 'ax5')\n",
    "    # debugLabelAxes(ax6, 'ax6')\n",
    "\n",
    "    # Plot CCF image =======================\n",
    "    plotXcorrTimeseries(ax1, lag, sTimes, ccf)\n",
    "\n",
    "    # Plot CCF-template (reference CCF) ===========\n",
    "    plotRCF(ax2, lag, rcf, snr_threshold)\n",
    "\n",
    "    # Plot number of stacked windows ==============\n",
    "    plotStackedWindowCount(ax3, nsw, sTimes)\n",
    "\n",
    "    # Plot histogram\n",
    "    plotSNRHistogram(ax4, snr, time_window)\n",
    "\n",
    "    # Plot Pearson correlation coefficient=========\n",
    "    plotPearsonCorrCoefficient(ax5, rcf, ccfMasked, sTimes)\n",
    "\n",
    "    # plot Timeshift =====================\n",
    "    plotEstimatedTimeshift(ax6, rcf, ccfMasked, lag, sTimes)\n",
    "#     plotEstimatedTimeshift(ax6, rcf, ccfMasked, lag, sTimes, underlay_reference_corr=True)\n",
    "\n",
    "    # Print and display\n",
    "    if pdf_file is not None:\n",
    "        pdf_out = PdfPages(pdf_file)\n",
    "        pdf_out.savefig(plt.gcf(), dpi=600)\n",
    "        pdf_out.close()\n",
    "\n",
    "    if png_file is not None:\n",
    "        plt.savefig(png_file, dpi=150)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 300 # +/-\n",
    "# SNR_THRESHOLD = 10\n",
    "SNR_THRESHOLD = 6\n",
    "\n",
    "ds = FederatedASDFDataSet.FederatedASDFDataSet(\"/g/data/ha3/Passive/SHARED_DATA/Index/asdf_files.txt\")\n",
    "\n",
    "SRC_FILES = [\"/g/data/ha3/am7399/shared/xcorr/AU/ARMA_CMSA/AU.ARMA.AU.CMSA.nc\",\n",
    "             \"/g/data/ha3/am7399/shared/xcorr/AU/KAKA_MTN/AU.KAKA.AU.MTN.nc\",\n",
    "             \"/g/data/ha3/am7399/shared/xcorr/AU/MEEK_MORW/AU.MEEK.AU.MORW.nc\",\n",
    "             \"/g/data/ha3/am7399/shared/xcorr/AU/MOO_TOO/AU.MOO.AU.TOO.nc\",\n",
    "             \"/g/data/ha3/am7399/shared/xcorr/AU/MUN_NWAO/AU.MUN.AU.NWAO.nc\",\n",
    "             \"/g/data/ha3/am7399/shared/xcorr/AU/RKGY_NWAO/AU.RKGY.AU.NWAO.nc\"]\n",
    "# SRC_FILES = [\"/g/data/ha3/am7399/shared/xcorr/AU/KAKA_MTN/AU.KAKA.AU.MTN.nc\"]\n",
    "# SRC_FILES = [\"/g/data/ha3/am7399/shared/xcorr/AU/MUN_NWAO/AU.MUN.AU.NWAO.nc\"]\n",
    "# SRC_FILES = [\"/g/data/ha3/am7399/shared/xcorr/AU/KAKA_MTN/AU.KAKA.AU.MTN.nc\",\n",
    "#              \"/g/data/ha3/am7399/shared/xcorr/AU/MUN_NWAO/AU.MUN.AU.NWAO.nc\"]\n",
    "\n",
    "save_plots = True\n",
    "for src_file in SRC_FILES:\n",
    "    if save_plots:\n",
    "        basename, _ = os.path.splitext(src_file)\n",
    "        png_file = basename + \".png\"\n",
    "        plotXcorrFile(src_file, ds, TIME_WINDOW, SNR_THRESHOLD, png_file=png_file, show=False)\n",
    "    else:\n",
    "        plotXcorrFile(src_file, ds, TIME_WINDOW, SNR_THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
