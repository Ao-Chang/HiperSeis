{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.dates\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import dateutil\n",
    "from dateutil import rrule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.ASDFdatabase import FederatedASDFDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from analytic_plot_utils import distance\n",
    "from netCDF4 import Dataset as NCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for plotting\n",
    "from textwrap import wrap\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FederatedASDFDataSet.FederatedASDFDataSet(\"/g/data/ha3/Passive/SHARED_DATA/Index/asdf_files.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_FILE = \"/g/data/ha3/am7399/shared/xcorr/AU/ARMA_CMSA/AU.ARMA.AU.CMSA.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_WINDOW = 300 # +/-\n",
    "SNR_THRESHOLD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read xcorr data\n",
    "xcdata = NCDataset(SRC_FILE, 'r')\n",
    "print(xcdata)\n",
    "\n",
    "xc_start_times = xcdata.variables['IntervalStartTimes'][:] # sTimes\n",
    "xc_end_times = xcdata.variables['IntervalEndTimes'][:] # eTimes\n",
    "xc_lag = xcdata.variables['lag'][:] # lag\n",
    "xc_xcorr = xcdata.variables['xcorr'][:, :] # xcorr\n",
    "xc_nStackedWindows = xcdata.variables['NumStackedWindows'][:] # nStackedWindows\n",
    "xcdata.close()\n",
    "xcdata = None\n",
    "\n",
    "start_utc_time = obspy.UTCDateTime(xc_start_times[0])\n",
    "end_utc_time = obspy.UTCDateTime(xc_end_times[-1])\n",
    "print((start_utc_time, end_utc_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = str(start_utc_time)\n",
    "end_time = str(end_utc_time)\n",
    "print((start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station codes from file name\n",
    "def stationCodes(filename):\n",
    "    path, fname = os.path.split(filename)\n",
    "    parts = fname.split('.')\n",
    "    sta1 = '.'.join(parts[0:2])\n",
    "    sta2 = '.'.join(parts[2:4])\n",
    "    return (sta1, sta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationCoords(federated_ds, code, datetime):\n",
    "    ds = federated_ds\n",
    "    net, sta = code.split('.')\n",
    "    sta_records = ds.get_stations(datetime, obspy.UTCDateTime(datetime) + 3600, network=net, station=sta)\n",
    "    z_records = [r for r in sta_records if r[3][1:3] == 'HZ']\n",
    "    assert len(z_records) == 1\n",
    "    z_record = z_records[0]\n",
    "    return z_record[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationDistance(federated_ds, code1, code2, datetime):\n",
    "    coords1 = stationCoords(federated_ds, code1, datetime)\n",
    "    coords2 = stationCoords(federated_ds, code2, datetime)\n",
    "    return distance(coords1, coords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_code, dest_code = stationCodes(SRC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationCoords(ds, origin_code, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationCoords(ds, dest_code, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = stationDistance(ds, origin_code, dest_code, start_time)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract primary data\n",
    "lagIndices = np.squeeze(np.argwhere(np.fabs(np.round(xc_lag, decimals=2)) == TIME_WINDOW))\n",
    "sTimes = xc_start_times\n",
    "lag = xc_lag[lagIndices[0]:lagIndices[1]]\n",
    "ccf = xc_xcorr[:, lagIndices[0]:lagIndices[1]]\n",
    "nsw = xc_nStackedWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derived quantities used by multiple axes\n",
    "zero_row_mask = (np.all(ccf == 0, axis=1))\n",
    "valid_mask = np.ones_like(ccf)\n",
    "valid_mask[zero_row_mask, :] = 0\n",
    "valid_mask = (valid_mask > 0)\n",
    "ccfMasked = np.ma.masked_array(ccf, mask=~valid_mask)\n",
    "snr = np.nanmax(ccfMasked, axis=1) / np.nanstd(ccfMasked, axis=1)\n",
    "if np.any(snr > SNR_THRESHOLD):\n",
    "    rcf = np.nanmean(ccfMasked[(snr > SNR_THRESHOLD), :], axis=0)\n",
    "else:\n",
    "    rcf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugLabelAxes(ax, label):\n",
    "    ax.text(0.5, 0.95, label, horizontalalignment='center', verticalalignment='top', transform=ax.transAxes, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestampToPlottableDatetime(data):\n",
    "    return data.transform(datetime.datetime.utcfromtimestamp).astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotXcorrTimeseries(ax, x_lag, y_times, xcorr_data):\n",
    "\n",
    "    np_times = np.array([datetime.datetime.utcfromtimestamp(v) for v in sTimes]).astype('datetime64[s]')\n",
    "    gx, gy = np.meshgrid(x_lag, np_times)\n",
    "    im = ax.pcolormesh(gx, gy, xcorr_data, cmap='RdYlBu_r', vmin=0, vmax=1, rasterized=True)\n",
    "\n",
    "    use_formatter = False\n",
    "    if use_formatter:\n",
    "        date_formatter = matplotlib.dates.DateFormatter(\"%Y-%m-%d\")\n",
    "        date_locator = matplotlib.dates.WeekdayLocator(byweekday=rrule.SU)\n",
    "        ax.yaxis.set_major_formatter(date_formatter)\n",
    "        ax.yaxis.set_major_locator(date_locator)\n",
    "    else:\n",
    "        labels = np.datetime_as_string(np_times, unit='D')\n",
    "        ax.set_yticks(np_times[::7])\n",
    "        ax.set_yticklabels(labels[::7])\n",
    "\n",
    "    ax.set_xlabel('Lag [s]')\n",
    "    ax.set_ylabel('Days')\n",
    "    \n",
    "    ax_pos = ax.get_position()\n",
    "    cax = plt.axes([ax_pos.x0 + 0.025, ax_pos.y1 - 0.1, 0.015, 0.08])\n",
    "\n",
    "    plt.colorbar(im, cax=cax, orientation='vertical', ticks=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ccf.shape)\n",
    "# print(type(ccf))\n",
    "# print(sTimes.shape)\n",
    "# plt.figure(figsize=(16,9))\n",
    "# plt.subplot(311)\n",
    "# plt.plot(sTimes, 'x')\n",
    "# ccf_mean = np.mean(ccf, axis=1)\n",
    "# print(ccf_mean.shape)\n",
    "# plt.subplot(312)\n",
    "# plt.plot(ccf_mean, '+')\n",
    "# plt.subplot(313)\n",
    "# plt.plot(sTimes, ccf_mean, 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xc_xcorr.shape)\n",
    "# print(type(xc_xcorr))\n",
    "# print(sTimes.shape)\n",
    "# plt.figure(figsize=(16,9))\n",
    "# plt.subplot(311)\n",
    "# plt.plot(sTimes, 'x')\n",
    "# xc_xcorr_mean = np.mean(xc_xcorr, axis=1)\n",
    "# print(xc_xcorr_mean.shape)\n",
    "# plt.subplot(312)\n",
    "# plt.plot(xc_xcorr_mean, '+')\n",
    "# plt.subplot(313)\n",
    "# plt.plot(sTimes, xc_xcorr_mean, 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRCF(ax, rcf):\n",
    "    if rcf is not None:\n",
    "        ax.axvline(x_lag[np.argmax(rcf)], c='#c66da9', lw=2,\n",
    "                    label = '{:5.2f} s'.format(x_lag[np.argmax(rcf)]))\n",
    "        ax.plot(x_lag, rcf, c='#42b3f4', \n",
    "                label=r\"Reference CCF \\n\"\n",
    "                       \"Based on Subset \\n\"\n",
    "                       \"with SNR > {}\".format(SNR_THRESHOLD))\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'REFERENCE CCF:\\nINSUFFICIENT SNR', horizontalalignment='center', \n",
    "         verticalalignment='center', transform=ax.transAxes, fontsize=20)\n",
    "\n",
    "    ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = np.nanmax(ccfMasked, axis=1) / np.nanstd(ccfMasked, axis=1)\n",
    "plt.plot(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,32))\n",
    "fig.suptitle(\"Station: {}, Dist. to {}: {:3.2f} km\".format(origin_code, dest_code, dist), fontsize = 16, y=1)\n",
    "\n",
    "ax1 = fig.add_axes([0.1, 0.075, 0.5, 0.725])\n",
    "debugLabelAxes(ax1, 'ax1')\n",
    "\n",
    "labelPad = 0.05\n",
    "ax2 = fig.add_axes([0.1, 0.8, 0.5, 0.175]) # reference CCF (accumulation of daily CCFs)\n",
    "ax3 = fig.add_axes([0.6, 0.075, 0.1, 0.725]) # number of stacked windows\n",
    "ax4 = fig.add_axes([0.6 + labelPad, 0.8 + labelPad, 0.345, 0.175 - labelPad]) # histogram\n",
    "ax5 = fig.add_axes([0.7, 0.075, 0.1, 0.725]) # Pearson coeff\n",
    "ax6 = fig.add_axes([0.8, 0.075, 0.195, 0.725]) # estimate timeshifts\n",
    "debugLabelAxes(ax2, 'ax2')\n",
    "debugLabelAxes(ax3, 'ax3')\n",
    "debugLabelAxes(ax4, 'ax4')\n",
    "debugLabelAxes(ax5, 'ax5')\n",
    "debugLabelAxes(ax6, 'ax6')\n",
    "\n",
    "# Plot CCF image =======================\n",
    "plotXcorrTimeseries(ax1, lag, sTimes, ccf)\n",
    "# gx, gy = np.meshgrid(lag, sTimes)\n",
    "# im = ax1.pcolormesh(gx, gy, ccf, cmap='RdYlBu_r', vmin=0, vmax=1, rasterized=True)\n",
    "\n",
    "# t = np.array(sTimes)\n",
    "\n",
    "# labels=[]\n",
    "# for st in sTimes: \n",
    "#     labels.append(obspy.UTCDateTime(st).strftime(\"%y-%m-%d\"))\n",
    "# ax1.set_yticks(sTimes[::7])\n",
    "# ax1.set_yticklabels(labels[::7])\n",
    "# ax1.set_xlabel('Lag [s]')\n",
    "# ax1.set_ylabel('Days')\n",
    "\n",
    "# fig.colorbar(im, cax=cax1, orientation='vertical', ticks=[0, 1])\n",
    "\n",
    "# Plot CCF-template =====================\n",
    "plotRCF(ax2, rcf)\n",
    "# rowMask = (np.sum(ccf, axis=1) > 0)\n",
    "# mask = np.ones_like(ccf)\n",
    "# for i in range(len(rowMask)):\n",
    "#     mask[i,:] *= rowMask[i] \n",
    "\n",
    "# ccfMasked = np.ma.masked_array(ccf, mask=~np.bool_(mask))\n",
    "# snr = np.nanmax(ccfMasked, axis=1) / np.nanstd(ccfMasked, axis=1)    \n",
    "\n",
    "# rcf = np.nanmean(ccfMasked[snr>SNR_THRESHOLD, :], axis=0)\n",
    "# ax2.axvline(lag[np.argmax(rcf)], c='#c66da9', lw=2,\n",
    "#             label = '%5.2f s'%(lag[np.argmax(rcf)]))\n",
    "# ax2.plot(lag, rcf, c='#42b3f4', \n",
    "#          label=r\"Reference CCF \"\n",
    "#                 \"\\n\"\n",
    "#                 \"Based on Subset \"\n",
    "#                 \"\\n\"\n",
    "#                 \"with SNR > %d\"%SNR_THRESHOLD)\n",
    "# ax2.set_xticklabels([])\n",
    "# ax2.legend()\n",
    "\n",
    "# Plot number of stacked windows ==============\n",
    "ax3.plot(nsw, sTimes, c='#529664')\n",
    "ax3.set_yticklabels([])\n",
    "ax3.set_xlabel('\\n'.join(wrap('# of Hourly Stacked Windows', 12)))\n",
    "xtl = ax3.get_xticklabels()\n",
    "xtl[0].set_visible(False)\n",
    "xtl[-1].set_visible(False)\n",
    "\n",
    "# Plot histogram\n",
    "ax4.hist(snr.compressed(), fc='#42b3f4', ec='none', bins=10)\n",
    "ax4.set_xlabel('SNR: Daily CCFs [-%d, %d]s'%(TIME_WINDOW, TIME_WINDOW))\n",
    "ax4.set_ylabel('Frequency')\n",
    "xtl = ax4.get_xticklabels()\n",
    "xtl[0].set_visible(False)\n",
    "xtl[-1].set_visible(False)\n",
    "\n",
    "# plot cc ===================\n",
    "# Compute CCave\n",
    "cc = []\n",
    "for row in ccfMasked:\n",
    "    if np.ma.is_masked(row):\n",
    "        cc.append(0)\n",
    "        continue\n",
    "    elif rcf is not None:\n",
    "        pcf, _ = scipy.stats.pearsonr(rcf, row)\n",
    "        cc.append(pcf)\n",
    "    else:\n",
    "        cc.append(np.nan)\n",
    "# end for\n",
    "cc = np.array(cc)\n",
    "ccav = np.mean(np.ma.masked_array(cc, mask=cc==0))\n",
    "\n",
    "ax5.plot(cc, sTimes, c='#d37f26')\n",
    "ax5.set_yticklabels([])\n",
    "ax5.set_xticks([0,1])\n",
    "ax5.set_xlabel('\\n'.join(wrap('Pearson Coeff. (RCF * CCF)', 15)))\n",
    "ax5.text(0.5, 0.95, '$CC_{ave}$=%3.3f'%ccav, horizontalalignment='center', \\\n",
    "         verticalalignment='center', transform=ax5.transAxes)\n",
    "\n",
    "# plot Timeshift =====================    \n",
    "corr = []\n",
    "for i, row in enumerate(ccfMasked):\n",
    "    if np.ma.is_masked(row): \n",
    "        corr.append(0)\n",
    "        continue\n",
    "        \n",
    "    if rcf is None:\n",
    "        corr.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    if cc[i] < 0.85*ccav:\n",
    "        corr.append(0)\n",
    "        continue\n",
    "\n",
    "    c3 = scipy.signal.correlate(rcf, row, mode='same')\n",
    "    c3 /= np.max(c3)\n",
    "    corr_lag = lag[np.argmax(c3)]\n",
    "    corr.append(corr_lag)    \n",
    "# end for\n",
    "corr = np.array(corr)\n",
    "ax6.plot(corr, sTimes, c='#f22e62', lw=1.5)\n",
    "ax6.set_yticklabels([])\n",
    "xtl = ax6.get_xticklabels()\n",
    "xtl[0].set_visible(False)\n",
    "xtl[-1].set_visible(False)\n",
    "ax6.set_xlabel('\\n'.join(wrap('Estimated Timeshift [s]: RCF * CCF', 15)))\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
