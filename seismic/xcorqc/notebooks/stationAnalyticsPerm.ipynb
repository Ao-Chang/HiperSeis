{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description:\n",
    "    Draft code for producing detailed plots of cross-correlation results \n",
    "    that are stored in netCDF files. A single pdf file containing plots\n",
    "    for each station-pair is output when the notebook runs to completion.\n",
    "References:\n",
    "\n",
    "CreationDate:   09/08/18\n",
    "Developer:      rakib.hassan@ga.gov.au\n",
    "\n",
    "Revision History:\n",
    "    LastUpdate:     09/08/18   RH\n",
    "    LastUpdate:     dd/mm/yyyy  Who     Optional description\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os, math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "#import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from descartes import PolygonPatch\n",
    "from shapely.geometry import Polygon\n",
    "#from matplotlib.patches import Ellipse\n",
    "\n",
    "from netCDF4 import Dataset as NCDataset\n",
    "from obspy.core import Stream, UTCDateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_root = os.path.abspath('../../..')\n",
    "if package_root not in sys.path:\n",
    "    sys.path.append(package_root)\n",
    "from seismic.xcorqc.correlator import Dataset\n",
    "\n",
    "#import matplotlib.dates as mdates\n",
    "from textwrap import wrap\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analytic_plot_utils import distance, drawBBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERM_STATION_NAME = 'QLP'\n",
    "CORR_PATH = '/g/data/ha3/rakib/xcorTest/7G/'\n",
    "\n",
    "TIME_WINDOW = 300 # +/-\n",
    "SNR_THRESHOLD = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/547/am7399/venv/py3.5.2/lib/python3.5/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "ds1 = Dataset('/g/data/ha3/Passive/_ANU/7G(2013-2015)/ASDF/7G(2013-2015).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = Dataset('/g/data/ha3/rakib/_ANU/7G(2013-2015)/refData/7G.refdata.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrFiles = glob.glob(CORR_PATH + '/*.%s.nc'%(PERM_STATION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n",
      "/home/547/am7399/venv/py3.5.2/lib/python3.5/site-packages/pyasdf/asdf_data_set.py:52: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  closure_warn(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centre: 143.330734, -29.030768\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "minLon = 1e32\n",
    "maxLon = -1e32\n",
    "minLat = 1e32\n",
    "maxLat = -1e32\n",
    "for s in ds1.stations:\n",
    "    lon,lat = ds1.stations_metadata[s].coordinates['longitude'], \\\n",
    "              ds1.stations_metadata[s].coordinates['latitude']\n",
    "    \n",
    "    minLon = min(lon, minLon)\n",
    "    maxLon = max(lon, maxLon)\n",
    "    minLat = min(lat, minLat)\n",
    "    maxLat = max(lat, maxLat)\n",
    "# end for\n",
    "\n",
    "m = Basemap(width=800000,height=800000,projection='lcc',\n",
    "            resolution='l',lat_1=minLat,lat_2=maxLat,\n",
    "            lat_0=(minLat+maxLat)/2., lon_0=(minLon + maxLon)/2.)\n",
    "# draw coastlines.\n",
    "m.drawcoastlines()\n",
    "\n",
    "#draw grid\n",
    "parallels = np.linspace(np.floor(minLat)-5, np.ceil(maxLat)+5, \\\n",
    "                        int((np.ceil(maxLat)+5) - (np.floor(minLat)-5))+1)\n",
    "m.drawparallels(parallels,labels=[True,True,False,False])\n",
    "meridians = np.linspace(np.floor(minLon)-5, np.ceil(maxLon)+5, \\\n",
    "                        int((np.ceil(maxLon)+5) - (np.floor(minLon)-5))+1)\n",
    "m.drawmeridians(meridians,labels=[False,False,True,True])\n",
    "\n",
    "# plot stations\n",
    "for s in ds1.stations:\n",
    "    lon,lat = ds1.stations_metadata[s].coordinates['longitude'], \\\n",
    "              ds1.stations_metadata[s].coordinates['latitude']\n",
    "\n",
    "    px,py = m(lon, lat)\n",
    "    pxl,pyl = m(lon+0.02, lat-0.1)\n",
    "    m.scatter(px, py, 50, marker='v', c='g', edgecolor='none')    \n",
    "    plt.annotate(s, xy=(pxl, pyl), fontsize=8)\n",
    "# end for\n",
    "\n",
    "# plot stations\n",
    "for s in ds2.stations:\n",
    "    lon,lat = ds2.stations_metadata[s].coordinates['longitude'], \\\n",
    "              ds2.stations_metadata[s].coordinates['latitude']\n",
    "\n",
    "    px,py = m(lon, lat)\n",
    "    pxl,pyl = m(lon+0.02, lat-0.1)\n",
    "    m.scatter(px, py, 50, marker='v', c='r', edgecolor='none', label='Perm. Station')    \n",
    "    plt.annotate(s, xy=(pxl, pyl), fontsize=8)\n",
    "# end for\n",
    "\n",
    "insetAx = fig.add_axes([0.75,0.75,0.125,0.125])\n",
    "mInset = Basemap(resolution='c', # c, l, i, h, f or None\n",
    "            ax=insetAx,\n",
    "            projection='merc',\n",
    "            lat_0=-20, lon_0=132,\n",
    "            llcrnrlon=110, llcrnrlat=-40, urcrnrlon=155, urcrnrlat=-10)\n",
    "#mInset.drawcoastlines()\n",
    "mInset.fillcontinents(color='lightgray')\n",
    "mInset.drawstates(color=\"grey\")\n",
    "\n",
    "drawBBox(minLon, minLat, maxLon, maxLat, mInset, fill='True', facecolor='k')\n",
    "\n",
    "print('centre: %lf, %lf'%(np.mean([minLon, maxLon]), np.mean([minLat, maxLat])))\n",
    "\n",
    "fig.axes[0].set_title(\"Deployment Name: 7G\", fontsize = 20, y=1.05)\n",
    "fig.axes[0].legend()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('./stations-perm.pdf')\n",
    "\n",
    "pdf = PdfPages('7G.pdf')\n",
    "pdf.savefig()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing station 0/44: CL45..\n",
      "Processing station 1/44: CP42..\n",
      "Processing station 2/44: CN41..\n",
      "Processing station 3/44: CM43..\n",
      "Processing station 4/44: CM42..\n",
      "Processing station 5/44: CK45..\n",
      "Processing station 6/44: CM40..\n",
      "Processing station 7/44: CL42..\n",
      "Processing station 8/44: CL40..\n",
      "Processing station 9/44: CK42..\n",
      "Processing station 10/44: CN42..\n",
      "Processing station 11/44: CR41..\n",
      "Processing station 12/44: CN45..\n",
      "Processing station 13/44: CK41..\n",
      "Processing station 14/44: CO46..\n",
      "Processing station 15/44: CL46..\n",
      "Processing station 16/44: CI45..\n",
      "Processing station 17/44: CP41..\n",
      "Processing station 18/44: CR40..\n",
      "Processing station 19/44: CP43..\n",
      "Processing station 20/44: CN44..\n",
      "Processing station 21/44: CK43..\n",
      "Processing station 22/44: CM44..\n",
      "Processing station 23/44: CN43..\n",
      "Processing station 24/44: CQ44..\n",
      "Processing station 25/44: CR45..\n",
      "Processing station 26/44: CQ46..\n",
      "Processing station 27/44: CQ40..\n",
      "Processing station 28/44: CR43..\n",
      "Processing station 29/44: CQ45..\n",
      "Processing station 30/44: CP40..\n",
      "Processing station 31/44: CI43..\n",
      "Processing station 32/44: CM46..\n",
      "Processing station 33/44: CQ43..\n",
      "Processing station 34/44: CL44..\n",
      "Processing station 35/44: CQ42..\n",
      "Processing station 36/44: CQ41..\n",
      "Processing station 37/44: CP44..\n",
      "Processing station 38/44: CJ47..\n",
      "Processing station 39/44: CK44..\n",
      "Processing station 40/44: CK40..\n",
      "Processing station 41/44: CP45..\n",
      "Processing station 42/44: CM45..\n",
      "Processing station 43/44: CN40..\n"
     ]
    }
   ],
   "source": [
    "for i, fn in enumerate(corrFiles):\n",
    "    #if 'CJ47.QLP' not in fn: continue\n",
    "\n",
    "    pair = os.path.basename(fn)\n",
    "    \n",
    "    sn = pair.split('.')[0]\n",
    "    print('Processing station {}/{}: {}..'.format(i+1, len(corrFiles), sn))\n",
    "    \n",
    "    origin = (ds1.stations_metadata[sn].coordinates['latitude'], \n",
    "              ds1.stations_metadata[sn].coordinates['longitude'])\n",
    "    dest = (ds2.stations_metadata[PERM_STATION_NAME].coordinates['latitude'], \n",
    "            ds2.stations_metadata[PERM_STATION_NAME].coordinates['longitude'])\n",
    "    \n",
    "    d = distance(origin, dest)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.suptitle(\"Station: %s, Dist. to %s: %3.2f km\"%(sn, PERM_STATION_NAME, d), \n",
    "                 fontsize = 16, y=1)\n",
    "\n",
    "    ax1 = fig.add_axes([0.1, 0.075, 0.5, 0.725])\n",
    "    cax1 = fig.add_axes([0.125, 0.7, 0.015, 0.05])\n",
    "\n",
    "    labelPad = 0.05\n",
    "    ax2 = fig.add_axes([0.1, 0.8, 0.5, 0.175])\n",
    "    ax3 = fig.add_axes([0.6, 0.075, 0.1, 0.725]) # stacked windows\n",
    "    ax4 = fig.add_axes([0.6+labelPad, 0.8+labelPad, 0.345, 0.175-labelPad]) # histogram\n",
    "    ax5 = fig.add_axes([0.7, 0.075, 0.1, 0.725]) # C3\n",
    "    ax6 = fig.add_axes([0.8, 0.075, 0.195, 0.725]) # timeshifts\n",
    "\n",
    "    # read data ==================\n",
    "    d = NCDataset(fn, 'r')\n",
    "    \n",
    "    sTimes = d.variables['IntervalStartTimes'][:]\n",
    "    lag = d.variables['lag'][:]\n",
    "    xcorr = d.variables['xcorr'][:, :]    \n",
    "    nStackedWindows = d.variables['NumStackedWindows'][:]\n",
    "    d.close()\n",
    "    d = None\n",
    "\n",
    "    ccfDict = defaultdict(list)\n",
    "    \n",
    "    lagIndices = np.squeeze(np.argwhere(np.fabs(np.round(lag, decimals=2)) == TIME_WINDOW))\n",
    "    #print lagIndices, lag[lagIndices]\n",
    "    ccfDict[pair] = {'start-times':sTimes, \n",
    "                     'lag':lag[lagIndices[0]:lagIndices[1]], \n",
    "                     'ccf':xcorr[:, lagIndices[0]:lagIndices[1]],\n",
    "                     'nsw':nStackedWindows}            \n",
    "    \n",
    "    sTimes = ccfDict[pair]['start-times']\n",
    "    lag = ccfDict[pair]['lag']\n",
    "    ccf = ccfDict[pair]['ccf']\n",
    "    \n",
    "    # Plot CCF image =======================\n",
    "    gx, gy = np.meshgrid(lag, sTimes)\n",
    "    \n",
    "    #print gx.shape\n",
    "    #print xcorr.shape\n",
    "        \n",
    "    im = ax1.pcolormesh(gx, gy, ccf, \n",
    "                        cmap='RdBu', vmin=0, vmax=1, rasterized=True)\n",
    "    \n",
    "    t = np.array(sTimes)\n",
    "    g = np.gradient(t)\n",
    "    indices = np.argwhere(g > (np.mean(g) + 2*np.std(g)))\n",
    "    \n",
    "    if (len(indices)>1):\n",
    "        for i,idx in enumerate(indices[::2]):\n",
    "            bx = np.array([np.min(gx), np.max(gx), np.max(gx), np.min(gx), np.min(gx)])\n",
    "            by = np.array([sTimes[idx], sTimes[idx], sTimes[indices[i+1]], sTimes[indices[i+1]], sTimes[idx]])\n",
    "\n",
    "            xy = zip(bx,by)\n",
    "            poly = Polygon(xy)\n",
    "            #ax1.add_patch(PolygonPatch(poly, facecolor='white', ec='red'))\n",
    "        # end for\n",
    "    # end if\n",
    "\n",
    "    labels=[]\n",
    "    for st in sTimes: \n",
    "        labels.append(UTCDateTime(st).strftime(\"%y-%m-%d\"))\n",
    "    ax1.set_yticks(sTimes[::7])\n",
    "    ax1.set_yticklabels(labels[::7])\n",
    "    ax1.set_xlabel('Lag [s]')\n",
    "    ax1.set_ylabel('Days')\n",
    "\n",
    "    fig.colorbar(im, cax=cax1, orientation='vertical', ticks=[0, 1])\n",
    "    \n",
    "    # Plot CCF-template =====================\n",
    "    rowMask = (np.sum(ccf, axis=1)>0)\n",
    "    mask = np.ones_like(ccf)\n",
    "    for i in range(len(rowMask)):\n",
    "        mask[i,:] *= rowMask[i] \n",
    "    \n",
    "    ccfMasked = np.ma.masked_array(ccf, mask=~np.bool_(mask))\n",
    "    snr = np.nanmax(ccfMasked, axis=1) / np.nanstd(ccfMasked, axis=1)    \n",
    "    \n",
    "    rcf = np.nanmean(ccfMasked[snr>SNR_THRESHOLD, :], axis=0)\n",
    "    ax2.axvline(lag[np.argmax(rcf)], c='#c66da9', lw=2,\n",
    "                label = '%5.2f s'%(lag[np.argmax(rcf)]))\n",
    "    ax2.plot(lag, rcf, c='#42b3f4', \n",
    "             label=r\"Reference CCF \"\n",
    "                    \"\\n\"\n",
    "                    \"Based on Subset \"\n",
    "                    \"\\n\"\n",
    "                    \"with SNR > %d\"%SNR_THRESHOLD)\n",
    "    ax2.set_xticklabels([])\n",
    "    ax2.legend()\n",
    "        \n",
    "    # Plot number of stacked windows ==============\n",
    "    ax3.plot(ccfDict[pair]['nsw'], sTimes, c='#529664')\n",
    "    ax3.set_yticklabels([])\n",
    "    ax3.set_xlabel('\\n'.join(wrap('# of Hourly Stacked Windows', 12)))\n",
    "    xtl = ax3.get_xticklabels()\n",
    "    xtl[0].set_visible(False)\n",
    "    xtl[-1].set_visible(False)\n",
    "    \n",
    "    # Plot histogram\n",
    "    ax4.hist(snr.compressed(), fc='#42b3f4', ec='none', bins=10)\n",
    "    ax4.set_xlabel('SNR: Daily CCFs [-%d, %d]s'%(TIME_WINDOW, TIME_WINDOW))\n",
    "    ax4.set_ylabel('Frequency')\n",
    "    xtl = ax4.get_xticklabels()\n",
    "    xtl[0].set_visible(False)\n",
    "    xtl[-1].set_visible(False)\n",
    "    \n",
    "    # plot cc ===================\n",
    "    # Compute CCave\n",
    "    cc = []\n",
    "    for row in ccfMasked:\n",
    "        if(np.ma.is_masked(row)): \n",
    "            cc.append(0)\n",
    "            continue\n",
    "            \n",
    "        pcf, _ = scipy.stats.pearsonr(rcf, row)\n",
    "        cc.append(pcf)\n",
    "    # end for\n",
    "    cc = np.array(cc)\n",
    "    ccav = np.mean(np.ma.masked_array(cc, mask=cc==0))\n",
    "    \n",
    "    ax5.plot(cc, sTimes, c='#d37f26')\n",
    "    ax5.set_yticklabels([])\n",
    "    ax5.set_xticks([0,1])\n",
    "    ax5.set_xlabel('\\n'.join(wrap('Pearson Coeff. (RCF * CCF)', 15)))\n",
    "    ax5.text(0.5, 0.95, '$CC_{ave}$=%3.3f'%ccav, horizontalalignment='center', \\\n",
    "             verticalalignment='center', transform=ax5.transAxes)\n",
    "    \n",
    "    # plot Timeshift =====================    \n",
    "    corr = []\n",
    "    for i, row in enumerate(ccfMasked):\n",
    "        if(np.ma.is_masked(row)): \n",
    "            corr.append(0)\n",
    "            continue\n",
    "        \n",
    "        if(cc[i] < 0.85*ccav):\n",
    "            corr.append(0)\n",
    "            continue\n",
    "            \n",
    "        c3 = scipy.signal.correlate(rcf, row, mode='same')\n",
    "        c3 /= np.max(c3)\n",
    "        lag = ccfDict[pair]['lag'][np.argmax(c3)]\n",
    "        corr.append(lag)    \n",
    "    # end for\n",
    "    corr = np.array(corr)\n",
    "    ax6.plot(corr, sTimes, c='#f22e62', lw=1.5)\n",
    "    ax6.set_yticklabels([])\n",
    "    xtl = ax6.get_xticklabels()\n",
    "    xtl[0].set_visible(False)\n",
    "    xtl[-1].set_visible(False)\n",
    "    ax6.set_xlabel('\\n'.join(wrap('Estimated Timeshift [s]: RCF * CCF', 15)))\n",
    "\n",
    "    pdf.savefig(fig)\n",
    "    fig.clf()\n",
    "    plt.close()\n",
    "    ccfDict = None\n",
    "    \n",
    "    gc.collect(2)    \n",
    "# end for\n",
    "\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
